{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "['male', 'female']\n",
      "Bacilli \n",
      "P-value: 0.040059\n",
      "Fusobacteria \n",
      "P-value: 0.000003\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.021050\n",
      "Alphaproteobacteria \n",
      "P-value: 0.038678\n",
      "Thermotogae \n",
      "P-value: 0.012158\n",
      "\n",
      "\n",
      "SleepPrior\n",
      "['less than 4', '4 to 7', 'more than 7']\n",
      "Flavobacteriia \n",
      "P-value: 0.038765\n",
      "Sphingobacteriia \n",
      "P-value: 0.026157\n",
      "\n",
      "\n",
      "Prescription\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "OralAntibiotics\n",
      "['within the last week', 'within the last year', 'not within the last year', 'within the last month', 'within the last 6 months']\n",
      "\n",
      "\n",
      "TopAntibiotics\n",
      "['within the last week', 'within the last year', 'not with in the last year', 'not within the last year', 'within the last month', 'within the last 6 months']\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.042631\n",
      "\n",
      "\n",
      "Eyes\n",
      "['hazel', 'green', 'blue', 'brown', 'black']\n",
      "\n",
      "\n",
      "Hands\n",
      "['right', 'left']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.002471\n",
      "Sphingobacteriia \n",
      "P-value: 0.045450\n",
      "Erysipelotrichi \n",
      "P-value: 0.035635\n",
      "Spirochaetes \n",
      "P-value: 0.034902\n",
      "Nostocophycideae \n",
      "P-value: 0.025699\n",
      "Mollicutes \n",
      "P-value: 0.030442\n",
      "\n",
      "\n",
      "Facial\n",
      "['combination', 'dry', 'oily']\n",
      "\n",
      "\n",
      "LastVomit\n",
      "['within the last week', 'more than a year ago', 'within the last year', 'today', 'within the last month']\n",
      "\n",
      "\n",
      "Snore\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "GrindTeeth\n",
      "['no', 'yes']\n",
      "Erysipelotrichi \n",
      "P-value: 0.025958\n",
      "\n",
      "\n",
      "EarInfect\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "AllergyTime\n",
      "['never', 'seasonally', 'rarely', 'chronically']\n",
      "Actinobacteria \n",
      "P-value: 0.039844\n",
      "\n",
      "\n",
      "OralSurgery\n",
      "['no', 'yes']\n",
      "Flavobacteriia \n",
      "P-value: 0.010887\n",
      "Sphingobacteriia \n",
      "P-value: 0.040144\n",
      "\n",
      "\n",
      "HeartDisease\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "BadTeeth\n",
      "['no', 'yes']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.020081\n",
      "\n",
      "\n",
      "GumDay\n",
      "['3-4', '5-6', '0', '1-2']\n",
      "Actinobacteria \n",
      "P-value: 0.019889\n",
      "\n",
      "\n",
      "YogurtWeek\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 6.0, 7.0]\n",
      "Bacteroidia \n",
      "P-value: 0.029318\n",
      "Gammaproteobacteria \n",
      "P-value: 0.005359\n",
      "\n",
      "\n",
      "TeaWeek\n",
      "['0', '6-10', '1-5', '11-15', '16-20']\n",
      "Fusobacteria \n",
      "P-value: 0.000684\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.001365\n",
      "Spirochaetes \n",
      "P-value: 0.009023\n",
      "\n",
      "\n",
      "CoffeeWeek\n",
      "['21-25', '1-5', '0', '6-10', '11-15', '16-20']\n",
      "\n",
      "\n",
      "SodaWeek\n",
      "['21-25', '0', '6-10', '1-5', '11-15']\n",
      "Sphingobacteriia \n",
      "P-value: 0.033900\n",
      "Thermotogae \n",
      "P-value: 0.043681\n",
      "\n",
      "\n",
      "FastFoodWeek\n",
      "['0', '1-5', '6-10', '11-15']\n",
      "\n",
      "\n",
      "EatOutWeek\n",
      "['5-6', '3-4', '0', '>14', '13-14', '11-12', '1-2', '9-10', '7-8']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.042724\n",
      "Erysipelotrichi \n",
      "P-value: 0.007412\n",
      "Mollicutes \n",
      "P-value: 0.015902\n",
      "Chlamydiia \n",
      "P-value: 0.009302\n",
      "GroupII \n",
      "P-value: 0.006932\n",
      "Deinococci \n",
      "P-value: 0.008552\n",
      "Synergistia \n",
      "P-value: 0.009621\n",
      "Oscillatoriophycideae \n",
      "P-value: 0.011697\n",
      "Opitutae \n",
      "P-value: 0.009323\n",
      "Thermoprotei \n",
      "P-value: 0.008400\n",
      "Anaerolineae \n",
      "P-value: 0.008473\n",
      "Deferribacteres \n",
      "P-value: 0.007748\n",
      "Nitriliruptoria \n",
      "P-value: 0.008487\n",
      "Acidobacteria \n",
      "P-value: 0.008629\n",
      "Thermotogae \n",
      "P-value: 0.009911\n",
      "Synechococcophycideae \n",
      "P-value: 0.008103\n",
      "Thermodesulfobacteria \n",
      "P-value: 0.008099\n",
      "Caldithrixae \n",
      "P-value: 0.008468\n",
      "Thermobacula \n",
      "P-value: 0.007760\n",
      "Fibrobacteria \n",
      "P-value: 0.008108\n",
      "Brocadiae \n",
      "P-value: 0.008181\n",
      "Holophagae \n",
      "P-value: 0.007943\n",
      "Nitrospira \n",
      "P-value: 0.007982\n",
      "Ktedonobacteria \n",
      "P-value: 0.008676\n",
      "Dehalococcoidetes \n",
      "P-value: 0.007882\n",
      "Acidimicrobiia \n",
      "P-value: 0.007938\n",
      "Leptospirae \n",
      "P-value: 0.008051\n",
      "Chrysiogenetes \n",
      "P-value: 0.008146\n",
      "Verrucomicrobiae \n",
      "P-value: 0.007988\n",
      "\n",
      "\n",
      "Straw\n",
      "['always', 'usually', 'never', 'often', 'rarely', 'sometimes']\n",
      "Bacteroidia \n",
      "P-value: 0.031503\n",
      "\n",
      "\n",
      "AddedSugar\n",
      "['always', 'never', 'often', 'rarely', 'sometimes']\n",
      "\n",
      "\n",
      "Spicy\n",
      "['no', 'yes']\n",
      "Actinobacteria \n",
      "P-value: 0.011335\n",
      "\n",
      "\n",
      "ShareDrink\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "Actinobacteria \n",
      "P-value: 0.042529\n",
      "\n",
      "\n",
      "MeatWeek\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
      "Actinobacteria \n",
      "P-value: 0.002560\n",
      "\n",
      "\n",
      "FreshWeek\n",
      "[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]\n",
      "Clostridia \n",
      "P-value: 0.005943\n",
      "Flavobacteriia \n",
      "P-value: 0.003561\n",
      "\n",
      "\n",
      "BrushTongue\n",
      "['no', 'yes']\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.045579\n",
      "Spirochaetes \n",
      "P-value: 0.009918\n",
      "\n",
      "\n",
      "BrushTeethWeek\n",
      "['21-25', '>25', '0', '6-10', '1-5', '11-15', '16-20']\n",
      "Fusobacteria \n",
      "P-value: 0.000166\n",
      "\n",
      "\n",
      "FlossWeek\n",
      "['21-25', '1-5', '0', '6-10', '11-15']\n",
      "\n",
      "\n",
      "DentistYear\n",
      "['>4', '3', '0', '2', '1', '4']\n",
      "\n",
      "\n",
      "Toothbrush\n",
      "['electric', 'manual', 'both']\n",
      "Flavobacteriia \n",
      "P-value: 0.035585\n",
      "\n",
      "\n",
      "Mouthwash\n",
      "['no', 'yes']\n",
      "Bacteroidia \n",
      "P-value: 0.005958\n",
      "Flavobacteriia \n",
      "P-value: 0.029428\n",
      "\n",
      "\n",
      "WashHandsEat\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "Alphaproteobacteria \n",
      "P-value: 0.047869\n",
      "Nostocophycideae \n",
      "P-value: 0.031806\n",
      "Oscillatoriophycideae \n",
      "P-value: 0.041011\n",
      "\n",
      "\n",
      "WashHandsRestroom\n",
      "[2.0, 3.0, 4.0, 5.0]\n",
      "Betaproteobacteria \n",
      "P-value: 0.039235\n",
      "\n",
      "\n",
      "ChangeToothbrush\n",
      "['every month', 'every three months', 'every year']\n",
      "\n",
      "\n",
      "OrthoDevice\n",
      "['>5 years', '5 years', '4 years', '3 years', 'none', '2 years', '1 year']\n",
      "\n",
      "\n",
      "Device\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "Stress\n",
      "[2.0, 3.0, 4.0, 5.0]\n",
      "\n",
      "\n",
      "HandleStress\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "Organized\n",
      "['no', 'yes']\n",
      "Flavobacteriia \n",
      "P-value: 0.006251\n",
      "Nostocophycideae \n",
      "P-value: 0.017072\n",
      "\n",
      "\n",
      "RateStress\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "\n",
      "\n",
      "AvgSleep\n",
      "['5-6', '3-4', '1-2', '9-10', '7-8']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.039586\n",
      "Erysipelotrichi \n",
      "P-value: 0.022484\n",
      "\n",
      "\n",
      "AvgWork\n",
      "['>31', '1-5', '6-10', '21-30', '11-15', '16-20']\n",
      "Fusobacteria \n",
      "P-value: 0.008180\n",
      "\n",
      "\n",
      "Setting\n",
      "['small town (<10,000 population)', 'rural', 'metroplex (>1,000,000)', 'suburb', 'large city (>100,000 - 1,000,000)', 'medium town (10,000 - 100,000)']\n",
      "\n",
      "\n",
      "UpDown\n",
      "['all equal amounts', 'stairs', 'elevator', 'escalator']\n",
      "Sphingobacteriia \n",
      "P-value: 0.024669\n",
      "\n",
      "\n",
      "Weight\n",
      "['226-250', '<100', '176-200', '126-150', '100-125', '151-175', '201-225', '251-275']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.019751\n",
      "Fusobacteria \n",
      "P-value: 0.001805\n",
      "\n",
      "\n",
      "ExerciseMonth\n",
      "['5-6', '3-4', '>10', '0', '1-2', '9-10', '7-8']\n",
      "Gammaproteobacteria \n",
      "P-value: 0.022708\n",
      "\n",
      "\n",
      "Orientation\n",
      "['homosexual', 'bisexual', 'heterosexual']\n",
      "\n",
      "\n",
      "ShareBathroom\n",
      "['>6', '3', '0', '5', '2', '1']\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.021829\n",
      "\n",
      "\n",
      "BooksYear\n",
      "['>25', '0', '1-5', '6-10', '11-15', '16-20']\n",
      "\n",
      "\n",
      "Alarms\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "Patience\n",
      "['always', 'usually', 'never', 'often', 'rarely', 'sometimes']\n",
      "Bacteroidia \n",
      "P-value: 0.026022\n",
      "Betaproteobacteria \n",
      "P-value: 0.024760\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.015431\n",
      "\n",
      "\n",
      "Lipstick\n",
      "['always', 'usually', 'never', 'often', 'rarely', 'sometimes']\n",
      "Fusobacteria \n",
      "P-value: 0.000724\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.043246\n",
      "\n",
      "\n",
      "IntroExtro\n",
      "['introvert', 'ambivert', 'extrovert']\n",
      "\n",
      "\n",
      "Relgious\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "OptiPessi\n",
      "['optimist', 'pessimist']\n",
      "Bacilli \n",
      "P-value: 0.009573\n",
      "Deltaproteobacteria \n",
      "P-value: 0.035320\n",
      "Mollicutes \n",
      "P-value: 0.045822\n",
      "Chlamydiia \n",
      "P-value: 0.046089\n",
      "GroupII \n",
      "P-value: 0.045779\n",
      "\n",
      "\n",
      "SexuallyActive\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "OralSex\n",
      "['no', 'yes']\n",
      "Betaproteobacteria \n",
      "P-value: 0.027464\n",
      "\n",
      "\n",
      "Music\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "Fusobacteria \n",
      "P-value: 0.048190\n",
      "Deltaproteobacteria \n",
      "P-value: 0.006696\n",
      "Alphaproteobacteria \n",
      "P-value: 0.029572\n",
      "\n",
      "\n",
      "AvgGrade\n",
      "['b', 'a', 'c']\n",
      "Bacteroidia \n",
      "P-value: 0.022325\n",
      "Deltaproteobacteria \n",
      "P-value: 0.031909\n",
      "Nostocophycideae \n",
      "P-value: 0.000607\n",
      "\n",
      "\n",
      "RateHappy\n",
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n",
      "\n",
      "\n",
      "Arts\n",
      "['no', 'yes']\n",
      "\n",
      "\n",
      "Kiss\n",
      "['no', 'yes']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "train_inputs = []\n",
    "train_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "\n",
    "#Enum for all the categories and their column number\n",
    "class Col(Enum):\n",
    "    Gender = 1\n",
    "    Menstrual = 2 \n",
    "    SleepPrior = 3 \n",
    "    Prescription = 4 \n",
    "    OralAntibiotics = 5 \n",
    "    TopAntibiotics = 6 \n",
    "    Eyes = 7 \n",
    "    Hands = 8 \n",
    "    Race = 9 \n",
    "    Feeling = 10 \n",
    "    Symptoms = 11 \n",
    "    Facial = 12 \n",
    "    LastVomit = 13 \n",
    "    EnvAllergies = 14 \n",
    "    Snore = 15 \n",
    "    GrindTeeth = 16 \n",
    "    EarInfect = 17 \n",
    "    AllergyTime = 18 \n",
    "    Skin = 19 \n",
    "    OralSurgery = 20 \n",
    "    HeartDisease = 21 \n",
    "    BadTeeth = 22 \n",
    "    EatPrior = 23 \n",
    "    DrinkPrior = 24 \n",
    "    GumDay = 25 \n",
    "    YogurtWeek = 26 \n",
    "    TeaWeek = 27 \n",
    "    CoffeeWeek = 28 \n",
    "    SodaWeek = 29 \n",
    "    FastFoodWeek = 30 \n",
    "    EatOutWeek = 31 \n",
    "    Straw = 32 \n",
    "    AddedSugar = 33 \n",
    "    Spicy = 34 \n",
    "    ShareDrink = 35 \n",
    "    MeatWeek = 36 \n",
    "    FreshWeek = 37 \n",
    "    BrushTongue = 38 \n",
    "    BrushTeethWeek = 39 \n",
    "    TobaccoWeek = 40 \n",
    "    FlossWeek = 41 \n",
    "    DentistYear = 42 \n",
    "    Toothbrush = 43 \n",
    "    Mouthwash = 44 \n",
    "    Toothpaste = 45 \n",
    "    WashHandsEat = 46 \n",
    "    WashHandsRestroom = 47 \n",
    "    ChangeToothbrush = 48 \n",
    "    BiteNails = 49 \n",
    "    OrthoDevice = 50 \n",
    "    Device = 51 \n",
    "    Stress = 52 \n",
    "    HandleStress = 53 \n",
    "    Organized = 54 \n",
    "    RateStress = 55 \n",
    "    AvgSleep = 56 \n",
    "    AvgWork = 57 \n",
    "    Setting = 58 \n",
    "    Environment = 59 \n",
    "    UpDown = 60 \n",
    "    Weight = 61 \n",
    "    ExerciseMonth = 62 \n",
    "    Transportation = 63 \n",
    "    Orientation = 64 \n",
    "    NearDogsWeek = 65 \n",
    "    NearCatsWeek = 66 \n",
    "    ShareBathroom = 67 \n",
    "    BooksYear = 68 \n",
    "    Alarms = 69 \n",
    "    Patience = 70 \n",
    "    Lipstick = 71 \n",
    "    IntroExtro = 72 \n",
    "    Relgious = 73 \n",
    "    OptiPessi = 74 \n",
    "    SexuallyActive = 75 \n",
    "    OralSex = 76 \n",
    "    Music = 77 \n",
    "    AvgGrade = 78 \n",
    "    RateHappy = 79 \n",
    "    Arts = 80 \n",
    "    Kiss = 81 \n",
    "    Roommates = 82 \n",
    "\n",
    "    \n",
    "#Enum for type of test\n",
    "class Test(Enum):\n",
    "    Ttest = 1\n",
    "    Anova = 2\n",
    "    \n",
    "\n",
    "def sleepPrior(category, data):\n",
    "    if category != Col.SleepPrior:\n",
    "        return data\n",
    "    \n",
    "    #if SleepPrior, manipulate the data so that the subcategories don't go over 7\n",
    "    #also create new subcategories to make it more general\n",
    "    data[category.name] = data[category.name].replace(['0', '1', '2', '3'], 'less than 4')\n",
    "    data[category.name] = data[category.name].replace(['4', '5', '6', '7'], '4 to 7')\n",
    "    data[category.name] = data[category.name].replace(['8', '9', '10', '11', '12'], 'more than 7')\n",
    "    return data\n",
    "\n",
    "\n",
    "def prescription(category, data):\n",
    "    if category != Col.Prescription:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that if the prescription column has a specific prescription, replace with yes\n",
    "    data[category.name] = data[category.name].replace(['None', 'none', 'no '], 'no')\n",
    "    data.loc[(data[category.name] != 'no') & (data[category.name] != 'No') & (data[category.name] != 'nan'), \n",
    "             category.name] = 'yes'\n",
    "    return data\n",
    "\n",
    "\n",
    "def eyes(category, data):\n",
    "    if category != Col.Eyes:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data to make it more generic\n",
    "    data[category.name] = data[category.name].replace('Green/blue/gold mix', 'hazel')\n",
    "    return data\n",
    "\n",
    "\n",
    "def perWeek(category, data):\n",
    "    if category not in (Col.TeaWeek, Col.CoffeeWeek, Col.SodaWeek, Col.FastFoodWeek, Col.BrushTeethWeek, \n",
    "                        Col.FlossWeek, Col.BooksYear, Col.GumDay, Col.EatOutWeek, Col.AvgSleep, Col.AvgWork, \n",
    "                        Col.ExerciseMonth) :\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so results don't show as dates\n",
    "    data[category.name] = data[category.name].replace('5-Jan', '1-5')\n",
    "    data[category.name] = data[category.name].replace('10-Jun', '6-10')\n",
    "    data[category.name] = data[category.name].replace('15-Nov', '11-15')\n",
    "    \n",
    "    data[category.name] = data[category.name].replace('2-Jan', '1-2')\n",
    "    data[category.name] = data[category.name].replace('4-Mar', '3-4')\n",
    "    data[category.name] = data[category.name].replace('6-May', '5-6')\n",
    "    data[category.name] = data[category.name].replace('8-Jul', '7-8')\n",
    "    data[category.name] = data[category.name].replace('10-Sep', '9-10')\n",
    "    data[category.name] = data[category.name].replace('12-Nov', '11-12')\n",
    "    \n",
    "    if category == Col.FlossWeek:\n",
    "        data[category.name] = data[category.name].replace('5-Nov', '11-15')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def numToWords(category, data):\n",
    "    if category not in (Col.AddedSugar, Col.Straw, Col.Lipstick):\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so results don't show as dates\n",
    "    data[category.name] = data[category.name].replace('1', 'never')\n",
    "    data[category.name] = data[category.name].replace('2', 'rarely')\n",
    "    data[category.name] = data[category.name].replace('3', 'sometimes')\n",
    "    data[category.name] = data[category.name].replace('4', 'often')\n",
    "    data[category.name] = data[category.name].replace('5', 'always')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def mouthwash(category, data):\n",
    "    if category != Col.Mouthwash:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that results are in form of yes or no\n",
    "    data.loc[(data[category.name] != 'never') & (data[category.name] != 'No') & (data[category.name] != 'nan'), \n",
    "             category.name] = 'yes'\n",
    "    data[category.name] = data[category.name].replace('never', 'no')\n",
    "    return data\n",
    "\n",
    "\n",
    "def religious(category, data):\n",
    "    if category != Col.Relgious:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that results are in form of yes or no\n",
    "    data.loc[(data[category.name] != 'No') & (data[category.name] != 'nan'), category.name] = 'yes'\n",
    "    data[category.name] = data[category.name].replace('never', 'no')\n",
    "    return data\n",
    "\n",
    "\n",
    "def orientation(category, data):\n",
    "    if category != Col.Orientation:\n",
    "        return data\n",
    "    \n",
    "    #fix spelling mistakes, change bicurious to bisexual to generalize data\n",
    "    data[category.name] = data[category.name].replace('hetrosexual', 'heterosexual')\n",
    "    data[category.name] = data[category.name].replace(['bicurious', 'Bicurious'], 'bisexual')\n",
    "    return data\n",
    "\n",
    "\n",
    "bactClassDict = {}\n",
    "    \n",
    "def runTests(data, category, outputMap, showAllClasses):\n",
    "    subcategory = []\n",
    "    categoryDF = []\n",
    "    bactClasses = []\n",
    "    sigClasses = []\n",
    "    inputs = []\n",
    "    \n",
    "    #decided not to do these groups\n",
    "    if category.name in ('Menstrual', 'Race', 'Feeling', 'Symptoms', 'EnvAllergies', 'Skin', 'EatPrior',\n",
    "                        'DrinkPrior', 'TobaccoWeek', 'Toothpaste', 'BiteNails', 'Transportation', 'Environment', \n",
    "                        'NearDogsWeek', 'NearCatsWeek'):\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # fix the inconsistant data\n",
    "    data = sleepPrior(category, data)\n",
    "    data = prescription(category, data)\n",
    "    data = eyes(category, data)\n",
    "    data = perWeek(category, data)\n",
    "    data = numToWords(category, data)\n",
    "    data = mouthwash(category, data)\n",
    "    data = religious(category, data)\n",
    "    data = orientation(category, data)\n",
    "\n",
    "    #change the category into its own separate dataframe\n",
    "\n",
    "    #get list of subcategories\n",
    "    try:\n",
    "        data[category.name] = data[category.name].str.lower()\n",
    "    except:\n",
    "        data[category.name]\n",
    "    subcategory = data[category.name].drop_duplicates().values.tolist()\n",
    "    \n",
    "    #remove nans (where people didn't put in an answer)\n",
    "    try:\n",
    "        subcategory = [subcat.lower().strip() for subcat in subcategory if str(subcat) != 'nan' \n",
    "                   and str(subcat) != 'don\\'t know' and str(subcat) != 'do not know' and str(subcat) != 'don?t know']\n",
    "    except:\n",
    "        subcategory = [subcat for subcat in subcategory if str(subcat) != 'nan' \n",
    "                   and str(subcat) != 'don\\'t know' and str(subcat) != 'do not know' and str(subcat) != 'don?t know']\n",
    "        \n",
    "    #remove any more duplicates\n",
    "    subcategory = list(set(subcategory))\n",
    "\n",
    "    #remove outliers/format the data for specific categories\n",
    "    if category == Col.Spicy:\n",
    "        subcategory.remove('sometimes')\n",
    "    if category == Col.Hands:\n",
    "        subcategory.remove('ambidextrous')\n",
    "    if category == Col.BrushTeethWeek:\n",
    "        subcategory.remove('42689');\n",
    "    \n",
    "\n",
    "    #decide on which test to use\n",
    "    if len(subcategory) == 2:\n",
    "        test = Test.Ttest\n",
    "    else:\n",
    "        test = Test.Anova\n",
    "        \n",
    "    #load dataframes for each subcategory of all bacterial classes\\n\",\n",
    "    for x in range(0, len(subcategory)):\n",
    "        categoryDF.append(data[data[category.name] == subcategory[x]].iloc[:, 83:125])\n",
    "        \n",
    "    print(category.name)\n",
    "    print(subcategory)\n",
    "        \n",
    "    #go through all bacterial classes to perform tests on them\n",
    "    sigClassCount = 0\n",
    "    for x in range(0, 42):\n",
    "        \n",
    "        #perform t-test if applicable\n",
    "        if test == Test.Ttest:\n",
    "            ttest = ttest_ind(categoryDF[0].iloc[:, x],categoryDF[1].iloc[:, x])\n",
    "            pvalue = ttest[1]\n",
    "            \n",
    "        #perform anova test is applicable\n",
    "        if test == Test.Anova:\n",
    "            #keep track of how many subcategories there are to put into anova test\n",
    "            arg = []\n",
    "            for y in range(0, len(subcategory)):\n",
    "                arg.append(categoryDF[y].iloc[:, x])\n",
    "            anova = stats.f_oneway(*(a for a in arg))\n",
    "            pvalue = anova[1]\n",
    "\n",
    "        #keep a list of all bacteria classes and their index\n",
    "        if len(bactClasses) != 42:\n",
    "            bactClasses.append(categoryDF[0].iloc[:,x].name)\n",
    "\n",
    "        #print classes that are significant\n",
    "        if pvalue <= 0.05 or showAllClasses:\n",
    "            #keep track of significant classes\n",
    "            sigClassCount += 1\n",
    "            className = categoryDF[0].iloc[:,x].name\n",
    "            if className not in bactClassDict:\n",
    "                bactClassDict[className] = 1\n",
    "            else:\n",
    "                bactClassDict[className] += 1\n",
    "            sigClasses.append(className)\n",
    "\n",
    "            print(categoryDF[0].iloc[:,x].name, \"\\nP-value: {:4.6f}\".format(pvalue))\n",
    "\n",
    "    # print out info for categories with high numbers of significant classes  \n",
    "#     if sigClassCount >= 4: \n",
    "#         catData = []\n",
    "#         print(sigClassCount)\n",
    "#         print(sigClasses)\n",
    "#         for subcat in data[category.name]:\n",
    "#             if subcat in subcategory:\n",
    "#                 catData.append(subcat)\n",
    "#         print(len(catData))\n",
    "#         print(catData)\n",
    "    \n",
    "    print('\\n')\n",
    "        \n",
    "    #get and set inputs, key = bactClass, value = list of all values under that class - Design 1\n",
    "#     for c in sigClasses:\n",
    "#         classValue = []\n",
    "#         for index, row in data.iterrows():\n",
    "#             if row[category.name] in subcategory:\n",
    "#                 classValue.append(row[c])\n",
    "#         inputs[c] = classValue\n",
    "#     print(inputs)\n",
    "\n",
    "#     #get and set inputs Design 2\n",
    "#     for index, row in data.iterrows():\n",
    "#         classValue = []\n",
    "#         for c in sigClasses:\n",
    "#             if row[category.name] in subcategory:\n",
    "#                 classValue.append(row[c])\n",
    "#         if row[category.name] in subcategory:\n",
    "#             inputs.append(classValue)\n",
    "#     print(len(inputs), inputs)\n",
    "    \n",
    "#     #add subcategories to outputMap\n",
    "#     outputMap[category.name] = subcategory\n",
    "#     print(outputMap)\n",
    "    \n",
    "#     #get and set outputs so that it looks like [a,b,c]\n",
    "#     outputs = []\n",
    "#     for index, row in data.iterrows():\n",
    "#         if row[category.name] in subcategory:\n",
    "#             outputs.append(row[category.name])\n",
    "#     print(len(outputs), outputs)\n",
    "    \n",
    "#     #replace string outputs with numbers\n",
    "#     if outputs and isinstance(outputs[0], str):\n",
    "#         for i in range(0, len(outputs)):\n",
    "#             outputs[i] = subcategory.index(outputs[i])\n",
    "#     print(len(outputs), outputs)\n",
    "    \n",
    "#     #separate training and testing data\n",
    "#     for i in range(0, len(inputs)):\n",
    "#         if i % 2 == 1:\n",
    "#             train_inputs.append(inputs[i])\n",
    "#             train_outputs.append(outputs[i])\n",
    "#         else:\n",
    "#             test_inputs.append(inputs[i])\n",
    "#             test_outputs.append(outputs[i])  \n",
    "    \n",
    "    \n",
    "\n",
    "class Main():\n",
    "    data = pd.read_csv('MasterSheet.csv')\n",
    "    outputMap = {}\n",
    "    showAllClasses = False\n",
    "    \n",
    "#     runTests(data, Col.Gender, outputMap, showAllClasses)\n",
    "    \n",
    "    for x in range(1, 82):\n",
    "        runTests(data, Col(x), outputMap, showAllClasses)\n",
    "        \n",
    "    #print out the highest appearing sig class\n",
    "#     sort = sorted(bactClassDict.items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(sort)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 53 samples\n",
      "Epoch 1/800\n",
      "53/53 [==============================] - 1s 27ms/step - loss: 2.2783 - acc: 0.5283 - val_loss: 2.2531 - val_acc: 0.5094\n",
      "Epoch 2/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 2.2470 - acc: 0.5283 - val_loss: 2.2212 - val_acc: 0.5094\n",
      "Epoch 3/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 2.2151 - acc: 0.5283 - val_loss: 2.1906 - val_acc: 0.5094\n",
      "Epoch 4/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 2.1852 - acc: 0.5283 - val_loss: 2.1608 - val_acc: 0.5094\n",
      "Epoch 5/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 2.1547 - acc: 0.5283 - val_loss: 2.1275 - val_acc: 0.5094\n",
      "Epoch 6/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 2.1205 - acc: 0.5283 - val_loss: 2.0894 - val_acc: 0.5094\n",
      "Epoch 7/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 2.0819 - acc: 0.5283 - val_loss: 2.0462 - val_acc: 0.5094\n",
      "Epoch 8/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 2.0384 - acc: 0.5283 - val_loss: 1.9974 - val_acc: 0.5094\n",
      "Epoch 9/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 1.9873 - acc: 0.5283 - val_loss: 1.9411 - val_acc: 0.5094\n",
      "Epoch 10/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 1.9300 - acc: 0.5283 - val_loss: 1.8788 - val_acc: 0.5094\n",
      "Epoch 11/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 1.8667 - acc: 0.5283 - val_loss: 1.8097 - val_acc: 0.5094\n",
      "Epoch 12/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 1.7968 - acc: 0.5283 - val_loss: 1.7344 - val_acc: 0.5094\n",
      "Epoch 13/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 1.7196 - acc: 0.5283 - val_loss: 1.6544 - val_acc: 0.5094\n",
      "Epoch 14/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 1.6381 - acc: 0.5283 - val_loss: 1.5714 - val_acc: 0.5094\n",
      "Epoch 15/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 1.5545 - acc: 0.5283 - val_loss: 1.4872 - val_acc: 0.5094\n",
      "Epoch 16/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 1.4699 - acc: 0.5283 - val_loss: 1.4039 - val_acc: 0.5094\n",
      "Epoch 17/800\n",
      "53/53 [==============================] - 0s 264us/step - loss: 1.3862 - acc: 0.5283 - val_loss: 1.3229 - val_acc: 0.5094\n",
      "Epoch 18/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 1.3061 - acc: 0.5283 - val_loss: 1.2457 - val_acc: 0.5094\n",
      "Epoch 19/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 1.2290 - acc: 0.5283 - val_loss: 1.1737 - val_acc: 0.5094\n",
      "Epoch 20/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 1.1571 - acc: 0.5283 - val_loss: 1.1085 - val_acc: 0.5094\n",
      "Epoch 21/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 1.0926 - acc: 0.5283 - val_loss: 1.0494 - val_acc: 0.5094\n",
      "Epoch 22/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 1.0338 - acc: 0.5283 - val_loss: 0.9969 - val_acc: 0.5094\n",
      "Epoch 23/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.9824 - acc: 0.5283 - val_loss: 0.9513 - val_acc: 0.5094\n",
      "Epoch 24/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.9373 - acc: 0.5283 - val_loss: 0.9121 - val_acc: 0.5094\n",
      "Epoch 25/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.8989 - acc: 0.5283 - val_loss: 0.8784 - val_acc: 0.5094\n",
      "Epoch 26/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.8662 - acc: 0.5283 - val_loss: 0.8495 - val_acc: 0.5094\n",
      "Epoch 27/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.8381 - acc: 0.5283 - val_loss: 0.8248 - val_acc: 0.5094\n",
      "Epoch 28/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.8140 - acc: 0.5283 - val_loss: 0.8040 - val_acc: 0.5094\n",
      "Epoch 29/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.7947 - acc: 0.5283 - val_loss: 0.7859 - val_acc: 0.5094\n",
      "Epoch 30/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.7799 - acc: 0.5283 - val_loss: 0.7709 - val_acc: 0.5094\n",
      "Epoch 31/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.7646 - acc: 0.5283 - val_loss: 0.7591 - val_acc: 0.5094\n",
      "Epoch 32/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7539 - acc: 0.5283 - val_loss: 0.7495 - val_acc: 0.5094\n",
      "Epoch 33/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.7449 - acc: 0.5283 - val_loss: 0.7418 - val_acc: 0.5094\n",
      "Epoch 34/800\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.7383 - acc: 0.5283 - val_loss: 0.7356 - val_acc: 0.5094\n",
      "Epoch 35/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.7331 - acc: 0.5283 - val_loss: 0.7306 - val_acc: 0.5094\n",
      "Epoch 36/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.7286 - acc: 0.5283 - val_loss: 0.7265 - val_acc: 0.5094\n",
      "Epoch 37/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7251 - acc: 0.5283 - val_loss: 0.7231 - val_acc: 0.5094\n",
      "Epoch 38/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7222 - acc: 0.5283 - val_loss: 0.7203 - val_acc: 0.5094\n",
      "Epoch 39/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7196 - acc: 0.5283 - val_loss: 0.7178 - val_acc: 0.5094\n",
      "Epoch 40/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.7169 - acc: 0.5283 - val_loss: 0.7157 - val_acc: 0.5094\n",
      "Epoch 41/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.7148 - acc: 0.5283 - val_loss: 0.7138 - val_acc: 0.5094\n",
      "Epoch 42/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7126 - acc: 0.5283 - val_loss: 0.7123 - val_acc: 0.5094\n",
      "Epoch 43/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7124 - acc: 0.5283 - val_loss: 0.7113 - val_acc: 0.5094\n",
      "Epoch 44/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.7091 - acc: 0.5283 - val_loss: 0.7104 - val_acc: 0.5094\n",
      "Epoch 45/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7079 - acc: 0.5283 - val_loss: 0.7097 - val_acc: 0.5094\n",
      "Epoch 46/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7073 - acc: 0.5283 - val_loss: 0.7092 - val_acc: 0.5094\n",
      "Epoch 47/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.7064 - acc: 0.5283 - val_loss: 0.7087 - val_acc: 0.5094\n",
      "Epoch 48/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.7056 - acc: 0.5283 - val_loss: 0.7079 - val_acc: 0.5094\n",
      "Epoch 49/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.7047 - acc: 0.5283 - val_loss: 0.7069 - val_acc: 0.5094\n",
      "Epoch 50/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.7039 - acc: 0.5283 - val_loss: 0.7059 - val_acc: 0.5094\n",
      "Epoch 51/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7041 - acc: 0.5283 - val_loss: 0.7050 - val_acc: 0.5094\n",
      "Epoch 52/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7038 - acc: 0.5283 - val_loss: 0.7043 - val_acc: 0.5094\n",
      "Epoch 53/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.7025 - acc: 0.5283 - val_loss: 0.7040 - val_acc: 0.5094\n",
      "Epoch 54/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.7019 - acc: 0.5283 - val_loss: 0.7038 - val_acc: 0.5094\n",
      "Epoch 55/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7019 - acc: 0.5283 - val_loss: 0.7040 - val_acc: 0.5094\n",
      "Epoch 56/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7015 - acc: 0.5283 - val_loss: 0.7039 - val_acc: 0.5094\n",
      "Epoch 57/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.7010 - acc: 0.5283 - val_loss: 0.7036 - val_acc: 0.5094\n",
      "Epoch 58/800\n",
      "53/53 [==============================] - 0s 244us/step - loss: 0.7008 - acc: 0.5283 - val_loss: 0.7032 - val_acc: 0.5094\n",
      "Epoch 59/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.7003 - acc: 0.5283 - val_loss: 0.7030 - val_acc: 0.5094\n",
      "Epoch 60/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.7000 - acc: 0.5283 - val_loss: 0.7026 - val_acc: 0.5094\n",
      "Epoch 61/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6998 - acc: 0.5283 - val_loss: 0.7022 - val_acc: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6994 - acc: 0.5283 - val_loss: 0.7018 - val_acc: 0.5094\n",
      "Epoch 63/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6992 - acc: 0.5283 - val_loss: 0.7014 - val_acc: 0.5094\n",
      "Epoch 64/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6989 - acc: 0.5283 - val_loss: 0.7011 - val_acc: 0.5094\n",
      "Epoch 65/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6991 - acc: 0.5283 - val_loss: 0.7006 - val_acc: 0.5094\n",
      "Epoch 66/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6984 - acc: 0.5283 - val_loss: 0.7005 - val_acc: 0.5094\n",
      "Epoch 67/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6991 - acc: 0.5283 - val_loss: 0.7004 - val_acc: 0.5094\n",
      "Epoch 68/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6979 - acc: 0.5283 - val_loss: 0.6999 - val_acc: 0.5094\n",
      "Epoch 69/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6981 - acc: 0.5283 - val_loss: 0.6996 - val_acc: 0.5094\n",
      "Epoch 70/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6975 - acc: 0.5283 - val_loss: 0.6992 - val_acc: 0.5094\n",
      "Epoch 71/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6981 - acc: 0.5283 - val_loss: 0.6989 - val_acc: 0.5094\n",
      "Epoch 72/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6979 - acc: 0.5283 - val_loss: 0.6988 - val_acc: 0.5094\n",
      "Epoch 73/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6985 - acc: 0.5283 - val_loss: 0.6986 - val_acc: 0.5094\n",
      "Epoch 74/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6977 - acc: 0.5283 - val_loss: 0.6985 - val_acc: 0.5094\n",
      "Epoch 75/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6986 - acc: 0.5283 - val_loss: 0.6984 - val_acc: 0.5094\n",
      "Epoch 76/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6977 - acc: 0.5283 - val_loss: 0.6983 - val_acc: 0.5094\n",
      "Epoch 77/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6973 - acc: 0.5283 - val_loss: 0.6983 - val_acc: 0.5094\n",
      "Epoch 78/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6966 - acc: 0.5283 - val_loss: 0.6983 - val_acc: 0.5094\n",
      "Epoch 79/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6965 - acc: 0.5283 - val_loss: 0.6984 - val_acc: 0.5094\n",
      "Epoch 80/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6973 - acc: 0.5283 - val_loss: 0.6989 - val_acc: 0.5094\n",
      "Epoch 81/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6965 - acc: 0.5283 - val_loss: 0.6991 - val_acc: 0.5094\n",
      "Epoch 82/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6963 - acc: 0.5283 - val_loss: 0.6989 - val_acc: 0.5094\n",
      "Epoch 83/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6966 - acc: 0.5283 - val_loss: 0.6984 - val_acc: 0.5094\n",
      "Epoch 84/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6960 - acc: 0.5283 - val_loss: 0.6983 - val_acc: 0.5094\n",
      "Epoch 85/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6960 - acc: 0.5283 - val_loss: 0.6980 - val_acc: 0.5094\n",
      "Epoch 86/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6961 - acc: 0.5283 - val_loss: 0.6979 - val_acc: 0.5094\n",
      "Epoch 87/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6957 - acc: 0.5283 - val_loss: 0.6976 - val_acc: 0.5094\n",
      "Epoch 88/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6955 - acc: 0.5283 - val_loss: 0.6973 - val_acc: 0.5094\n",
      "Epoch 89/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6959 - acc: 0.5283 - val_loss: 0.6970 - val_acc: 0.5094\n",
      "Epoch 90/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6957 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 91/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6960 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 92/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6955 - acc: 0.5283 - val_loss: 0.6970 - val_acc: 0.5094\n",
      "Epoch 93/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6953 - acc: 0.5283 - val_loss: 0.6973 - val_acc: 0.5094\n",
      "Epoch 94/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6967 - acc: 0.5283 - val_loss: 0.6978 - val_acc: 0.5094\n",
      "Epoch 95/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6955 - acc: 0.5283 - val_loss: 0.6976 - val_acc: 0.5094\n",
      "Epoch 96/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6956 - acc: 0.5283 - val_loss: 0.6977 - val_acc: 0.5094\n",
      "Epoch 97/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6974 - val_acc: 0.5094\n",
      "Epoch 98/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6951 - acc: 0.5283 - val_loss: 0.6971 - val_acc: 0.5094\n",
      "Epoch 99/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6952 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 100/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6953 - acc: 0.5283 - val_loss: 0.6970 - val_acc: 0.5094\n",
      "Epoch 101/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6948 - acc: 0.5283 - val_loss: 0.6968 - val_acc: 0.5094\n",
      "Epoch 102/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6967 - val_acc: 0.5094\n",
      "Epoch 103/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 104/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6947 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 105/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6972 - val_acc: 0.5094\n",
      "Epoch 106/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6947 - acc: 0.5283 - val_loss: 0.6973 - val_acc: 0.5094\n",
      "Epoch 107/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6949 - acc: 0.5283 - val_loss: 0.6974 - val_acc: 0.5094\n",
      "Epoch 108/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6955 - acc: 0.5283 - val_loss: 0.6981 - val_acc: 0.5094\n",
      "Epoch 109/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6949 - acc: 0.5283 - val_loss: 0.6980 - val_acc: 0.5094\n",
      "Epoch 110/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6974 - val_acc: 0.5094\n",
      "Epoch 111/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6969 - val_acc: 0.5094\n",
      "Epoch 112/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6936 - acc: 0.5283 - val_loss: 0.6960 - val_acc: 0.5094\n",
      "Epoch 113/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 114/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6947 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 115/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6957 - acc: 0.5094 - val_loss: 0.6958 - val_acc: 0.4906\n",
      "Epoch 116/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6959 - acc: 0.5094 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 117/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6951 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 118/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6958 - val_acc: 0.5094\n",
      "Epoch 119/800\n",
      "53/53 [==============================] - 0s 151us/step - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6966 - val_acc: 0.5094\n",
      "Epoch 120/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6973 - val_acc: 0.5094\n",
      "Epoch 121/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6941 - acc: 0.5283 - val_loss: 0.6976 - val_acc: 0.5094\n",
      "Epoch 122/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6979 - val_acc: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6951 - acc: 0.5283 - val_loss: 0.6977 - val_acc: 0.5094\n",
      "Epoch 124/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6939 - acc: 0.5283 - val_loss: 0.6966 - val_acc: 0.5094\n",
      "Epoch 125/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6799 - acc: 0.625 - 0s 151us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6958 - val_acc: 0.5094\n",
      "Epoch 126/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 127/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n",
      "Epoch 128/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 129/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n",
      "Epoch 130/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 131/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6958 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 132/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 133/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6936 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 134/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6937 - acc: 0.5283 - val_loss: 0.6958 - val_acc: 0.5094\n",
      "Epoch 135/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 136/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6937 - acc: 0.5283 - val_loss: 0.6960 - val_acc: 0.5094\n",
      "Epoch 137/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6960 - val_acc: 0.5094\n",
      "Epoch 138/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5094\n",
      "Epoch 139/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 140/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 141/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6955 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 142/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 143/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6943 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 144/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 145/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6942 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 146/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6944 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 147/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 148/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6942 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 149/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 150/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6950 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 151/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 152/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 153/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5094\n",
      "Epoch 154/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6965 - val_acc: 0.5094\n",
      "Epoch 155/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6963 - val_acc: 0.5094\n",
      "Epoch 156/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6949 - acc: 0.5283 - val_loss: 0.6971 - val_acc: 0.5094\n",
      "Epoch 157/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6967 - val_acc: 0.5094\n",
      "Epoch 158/800\n",
      "53/53 [==============================] - 0s 151us/step - loss: 0.6949 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 159/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 160/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6950 - val_acc: 0.5094\n",
      "Epoch 161/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 162/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6947 - val_acc: 0.5094\n",
      "Epoch 163/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 164/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 165/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 166/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 167/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 168/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6939 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 169/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 170/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6934 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 171/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6937 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 172/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 173/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 174/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 175/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6964 - val_acc: 0.5094\n",
      "Epoch 176/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6976 - val_acc: 0.5094\n",
      "Epoch 177/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6977 - val_acc: 0.5094\n",
      "Epoch 178/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6973 - val_acc: 0.5094\n",
      "Epoch 179/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6965 - val_acc: 0.5094\n",
      "Epoch 180/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 181/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 182/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 183/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 184/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 185/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6936 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 186/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6939 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 187/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 188/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 189/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6945 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 190/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 191/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n",
      "Epoch 192/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 193/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6947 - val_acc: 0.5094\n",
      "Epoch 194/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6947 - val_acc: 0.5094\n",
      "Epoch 195/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6950 - val_acc: 0.5094\n",
      "Epoch 196/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6950 - val_acc: 0.5094\n",
      "Epoch 197/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 198/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 199/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6934 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 200/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 201/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 202/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 203/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 204/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 205/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 206/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 207/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 208/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 209/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 210/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 211/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6939 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 212/800\n",
      "53/53 [==============================] - 0s 357us/step - loss: 0.6939 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 213/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6849 - acc: 0.625 - 0s 207us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 214/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 215/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 216/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 217/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 218/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 219/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 220/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 221/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 222/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 223/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 224/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6942 - acc: 0.5283 - val_loss: 0.6960 - val_acc: 0.5094\n",
      "Epoch 225/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 226/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 227/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6936 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 228/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 229/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 230/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 231/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6928 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 232/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 233/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6943 - acc: 0.4528 - val_loss: 0.6940 - val_acc: 0.4717\n",
      "Epoch 234/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6944 - acc: 0.4528 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 235/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 236/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 237/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6952 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 238/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 239/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 240/800\n",
      "53/53 [==============================] - 0s 151us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 241/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 242/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 243/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 207us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 244/800\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6937 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 245/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 246/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 247/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 248/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 249/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 250/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 251/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 252/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 253/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 254/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6919 - acc: 0.5283 - val_loss: 0.6951 - val_acc: 0.5094\n",
      "Epoch 255/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5094\n",
      "Epoch 256/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6965 - val_acc: 0.5094\n",
      "Epoch 257/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6964 - val_acc: 0.5094\n",
      "Epoch 258/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 259/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 260/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 261/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 262/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 263/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 264/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 265/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6934 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 266/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 267/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 268/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 269/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 270/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 271/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6947 - val_acc: 0.5094\n",
      "Epoch 272/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6946 - val_acc: 0.5094\n",
      "Epoch 273/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6950 - val_acc: 0.5094\n",
      "Epoch 274/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 275/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 276/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6938 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 277/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 278/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 279/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 280/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 281/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 282/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 283/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 284/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6930 - acc: 0.5283 - val_loss: 0.6954 - val_acc: 0.5094\n",
      "Epoch 285/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n",
      "Epoch 286/800\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6929 - acc: 0.5283 - val_loss: 0.6946 - val_acc: 0.5094\n",
      "Epoch 287/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 288/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 289/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 290/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6919 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 291/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 292/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 293/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6933 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 294/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6934 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 295/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6932 - acc: 0.5283 - val_loss: 0.6936 - val_acc: 0.5094\n",
      "Epoch 296/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 297/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 298/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6937 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 299/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 300/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 301/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6919 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 302/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 303/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 305/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6936 - val_acc: 0.5094\n",
      "Epoch 306/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 307/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6923 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 308/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6935 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 309/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6939 - val_acc: 0.5094\n",
      "Epoch 310/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 311/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 312/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 313/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 314/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 315/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 316/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 317/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6931 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 318/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 319/800\n",
      "53/53 [==============================] - 0s 244us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 320/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6919 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 321/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6925 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 322/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6920 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 323/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 324/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6921 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 325/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6918 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 326/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6915 - acc: 0.5283 - val_loss: 0.6947 - val_acc: 0.5094\n",
      "Epoch 327/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6946 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 328/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6940 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 329/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6915 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 330/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.6922 - acc: 0.5283 - val_loss: 0.6937 - val_acc: 0.5094\n",
      "Epoch 331/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 332/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6932 - acc: 0.4717 - val_loss: 0.6941 - val_acc: 0.4528\n",
      "Epoch 333/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6949 - acc: 0.3774 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 334/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 335/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6924 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 336/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6916 - acc: 0.5283 - val_loss: 0.6941 - val_acc: 0.5094\n",
      "Epoch 337/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6915 - acc: 0.5283 - val_loss: 0.6943 - val_acc: 0.5094\n",
      "Epoch 338/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6909 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 339/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.531 - 0s 263us/step - loss: 0.6911 - acc: 0.5283 - val_loss: 0.6962 - val_acc: 0.5094\n",
      "Epoch 340/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6916 - acc: 0.5283 - val_loss: 0.6972 - val_acc: 0.5094\n",
      "Epoch 341/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6927 - acc: 0.5283 - val_loss: 0.6977 - val_acc: 0.5094\n",
      "Epoch 342/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6926 - acc: 0.5283 - val_loss: 0.6970 - val_acc: 0.5094\n",
      "Epoch 343/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6910 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 344/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6900 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 345/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6899 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 346/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6911 - acc: 0.5094 - val_loss: 0.6951 - val_acc: 0.4151\n",
      "Epoch 347/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6917 - acc: 0.5094 - val_loss: 0.6956 - val_acc: 0.4340\n",
      "Epoch 348/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6921 - acc: 0.5094 - val_loss: 0.6955 - val_acc: 0.3962\n",
      "Epoch 349/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6918 - acc: 0.4906 - val_loss: 0.6954 - val_acc: 0.4151\n",
      "Epoch 350/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6900 - acc: 0.5660 - val_loss: 0.6950 - val_acc: 0.5094\n",
      "Epoch 351/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6855 - acc: 0.531 - 0s 188us/step - loss: 0.6890 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n",
      "Epoch 352/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6906 - acc: 0.5283 - val_loss: 0.6959 - val_acc: 0.5094\n",
      "Epoch 353/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6882 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5094\n",
      "Epoch 354/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6881 - acc: 0.5283 - val_loss: 0.6961 - val_acc: 0.5094\n",
      "Epoch 355/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6876 - acc: 0.5283 - val_loss: 0.6959 - val_acc: 0.5094\n",
      "Epoch 356/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6878 - acc: 0.5283 - val_loss: 0.6954 - val_acc: 0.5094\n",
      "Epoch 357/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.6876 - acc: 0.5283 - val_loss: 0.6953 - val_acc: 0.5094\n",
      "Epoch 358/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6831 - acc: 0.500 - 0s 282us/step - loss: 0.6859 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 359/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6854 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 360/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6850 - acc: 0.5283 - val_loss: 0.6956 - val_acc: 0.5094\n",
      "Epoch 361/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6850 - acc: 0.5283 - val_loss: 0.6957 - val_acc: 0.5094\n",
      "Epoch 362/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6844 - acc: 0.5283 - val_loss: 0.6955 - val_acc: 0.5094\n",
      "Epoch 363/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6839 - acc: 0.5283 - val_loss: 0.6952 - val_acc: 0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6835 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 365/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.6839 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 366/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.6833 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 367/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.6823 - acc: 0.5283 - val_loss: 0.6945 - val_acc: 0.5094\n",
      "Epoch 368/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6823 - acc: 0.5283 - val_loss: 0.6948 - val_acc: 0.5094\n",
      "Epoch 369/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.6824 - acc: 0.5283 - val_loss: 0.6949 - val_acc: 0.5094\n",
      "Epoch 370/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6827 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 371/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6808 - acc: 0.5283 - val_loss: 0.6944 - val_acc: 0.5094\n",
      "Epoch 372/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6804 - acc: 0.5283 - val_loss: 0.6942 - val_acc: 0.5094\n",
      "Epoch 373/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6797 - acc: 0.5283 - val_loss: 0.6940 - val_acc: 0.5094\n",
      "Epoch 374/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.6792 - acc: 0.5283 - val_loss: 0.6938 - val_acc: 0.5094\n",
      "Epoch 375/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.6768 - acc: 0.5283 - val_loss: 0.6934 - val_acc: 0.5094\n",
      "Epoch 376/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6738 - acc: 0.5283 - val_loss: 0.6905 - val_acc: 0.5094\n",
      "Epoch 377/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6576 - acc: 0.5283 - val_loss: 0.6767 - val_acc: 0.5094\n",
      "Epoch 378/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6299 - acc: 0.5849 - val_loss: 0.7068 - val_acc: 0.6038\n",
      "Epoch 379/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.6496 - acc: 0.6981 - val_loss: 0.6560 - val_acc: 0.6415\n",
      "Epoch 380/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6087 - acc: 0.6792 - val_loss: 0.6476 - val_acc: 0.6792\n",
      "Epoch 381/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5977 - acc: 0.6792 - val_loss: 0.6449 - val_acc: 0.6604\n",
      "Epoch 382/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.5859 - acc: 0.7170 - val_loss: 0.6384 - val_acc: 0.6792\n",
      "Epoch 383/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.5658 - acc: 0.7358 - val_loss: 0.6323 - val_acc: 0.6604\n",
      "Epoch 384/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5636 - acc: 0.6792 - val_loss: 0.6307 - val_acc: 0.6792\n",
      "Epoch 385/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.5518 - acc: 0.6981 - val_loss: 0.6430 - val_acc: 0.6604\n",
      "Epoch 386/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5477 - acc: 0.6981 - val_loss: 0.6315 - val_acc: 0.6604\n",
      "Epoch 387/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5381 - acc: 0.6792 - val_loss: 0.6373 - val_acc: 0.6226\n",
      "Epoch 388/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5420 - acc: 0.7170 - val_loss: 0.6462 - val_acc: 0.6792\n",
      "Epoch 389/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.5287 - acc: 0.7170 - val_loss: 0.6519 - val_acc: 0.6792\n",
      "Epoch 390/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.5247 - acc: 0.7170 - val_loss: 0.6385 - val_acc: 0.6604\n",
      "Epoch 391/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5236 - acc: 0.6792 - val_loss: 0.6370 - val_acc: 0.6415\n",
      "Epoch 392/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.5227 - acc: 0.6981 - val_loss: 0.6339 - val_acc: 0.6604\n",
      "Epoch 393/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5137 - acc: 0.7170 - val_loss: 0.6499 - val_acc: 0.6792\n",
      "Epoch 394/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5358 - acc: 0.7170 - val_loss: 0.6622 - val_acc: 0.6792\n",
      "Epoch 395/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5494 - acc: 0.6604 - val_loss: 0.6439 - val_acc: 0.6604\n",
      "Epoch 396/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.5155 - acc: 0.7547 - val_loss: 0.6367 - val_acc: 0.6604\n",
      "Epoch 397/800\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.5054 - acc: 0.7358 - val_loss: 0.6459 - val_acc: 0.6981\n",
      "Epoch 398/800\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5082 - acc: 0.6981 - val_loss: 0.6429 - val_acc: 0.6792\n",
      "Epoch 399/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.5049 - acc: 0.7170 - val_loss: 0.6424 - val_acc: 0.6604\n",
      "Epoch 400/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.5496 - acc: 0.7170 - val_loss: 0.6598 - val_acc: 0.6415\n",
      "Epoch 401/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.5083 - acc: 0.7170 - val_loss: 0.6430 - val_acc: 0.6792\n",
      "Epoch 402/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4949 - acc: 0.6981 - val_loss: 0.6871 - val_acc: 0.6415\n",
      "Epoch 403/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.5371 - acc: 0.7358 - val_loss: 0.6704 - val_acc: 0.6604\n",
      "Epoch 404/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5081 - acc: 0.6981 - val_loss: 0.6433 - val_acc: 0.6604\n",
      "Epoch 405/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.5166 - acc: 0.6981 - val_loss: 0.6646 - val_acc: 0.6604\n",
      "Epoch 406/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.5098 - acc: 0.7358 - val_loss: 0.6502 - val_acc: 0.6604\n",
      "Epoch 407/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4844 - acc: 0.7358 - val_loss: 0.6679 - val_acc: 0.6604\n",
      "Epoch 408/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.5127 - acc: 0.7358 - val_loss: 0.6836 - val_acc: 0.6604\n",
      "Epoch 409/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.5031 - acc: 0.7358 - val_loss: 0.6510 - val_acc: 0.6792\n",
      "Epoch 410/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4878 - acc: 0.7170 - val_loss: 0.6653 - val_acc: 0.6792\n",
      "Epoch 411/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.5141 - acc: 0.7358 - val_loss: 0.6578 - val_acc: 0.6604\n",
      "Epoch 412/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4976 - acc: 0.7170 - val_loss: 0.6506 - val_acc: 0.6604\n",
      "Epoch 413/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4830 - acc: 0.7358 - val_loss: 0.6551 - val_acc: 0.6604\n",
      "Epoch 414/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4814 - acc: 0.6981 - val_loss: 0.6576 - val_acc: 0.6604\n",
      "Epoch 415/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4811 - acc: 0.6981 - val_loss: 0.6547 - val_acc: 0.6792\n",
      "Epoch 416/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4775 - acc: 0.6981 - val_loss: 0.6513 - val_acc: 0.6604\n",
      "Epoch 417/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4768 - acc: 0.7170 - val_loss: 0.6533 - val_acc: 0.6604\n",
      "Epoch 418/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4792 - acc: 0.7736 - val_loss: 0.6563 - val_acc: 0.6604\n",
      "Epoch 419/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4841 - acc: 0.7170 - val_loss: 0.6633 - val_acc: 0.6604\n",
      "Epoch 420/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4763 - acc: 0.6981 - val_loss: 0.6568 - val_acc: 0.6604\n",
      "Epoch 421/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.4741 - acc: 0.718 - 0s 169us/step - loss: 0.4749 - acc: 0.7358 - val_loss: 0.6599 - val_acc: 0.6604\n",
      "Epoch 422/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4704 - acc: 0.7170 - val_loss: 0.6679 - val_acc: 0.6604\n",
      "Epoch 423/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4695 - acc: 0.7170 - val_loss: 0.6732 - val_acc: 0.6604\n",
      "Epoch 424/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4690 - acc: 0.7170 - val_loss: 0.6735 - val_acc: 0.6604\n",
      "Epoch 425/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4713 - acc: 0.7170 - val_loss: 0.6684 - val_acc: 0.6604\n",
      "Epoch 426/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4719 - acc: 0.7170 - val_loss: 0.6642 - val_acc: 0.6604\n",
      "Epoch 427/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4677 - acc: 0.7358 - val_loss: 0.6663 - val_acc: 0.6981\n",
      "Epoch 428/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4711 - acc: 0.7358 - val_loss: 0.6660 - val_acc: 0.6604\n",
      "Epoch 429/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4645 - acc: 0.7358 - val_loss: 0.6685 - val_acc: 0.6604\n",
      "Epoch 430/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4712 - acc: 0.7170 - val_loss: 0.6752 - val_acc: 0.6604\n",
      "Epoch 431/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4643 - acc: 0.7358 - val_loss: 0.6723 - val_acc: 0.6604\n",
      "Epoch 432/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4599 - acc: 0.7358 - val_loss: 0.6707 - val_acc: 0.6604\n",
      "Epoch 433/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4578 - acc: 0.7358 - val_loss: 0.6732 - val_acc: 0.6792\n",
      "Epoch 434/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4554 - acc: 0.7170 - val_loss: 0.6729 - val_acc: 0.6604\n",
      "Epoch 435/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4550 - acc: 0.7358 - val_loss: 0.6736 - val_acc: 0.6415\n",
      "Epoch 436/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4530 - acc: 0.7358 - val_loss: 0.6758 - val_acc: 0.6604\n",
      "Epoch 437/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4601 - acc: 0.7170 - val_loss: 0.6767 - val_acc: 0.6792\n",
      "Epoch 438/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4596 - acc: 0.7547 - val_loss: 0.6879 - val_acc: 0.6792\n",
      "Epoch 439/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4597 - acc: 0.7358 - val_loss: 0.6836 - val_acc: 0.6415\n",
      "Epoch 440/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4488 - acc: 0.7547 - val_loss: 0.6904 - val_acc: 0.6415\n",
      "Epoch 441/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4594 - acc: 0.6981 - val_loss: 0.6950 - val_acc: 0.6604\n",
      "Epoch 442/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4579 - acc: 0.7170 - val_loss: 0.6916 - val_acc: 0.6981\n",
      "Epoch 443/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4444 - acc: 0.7925 - val_loss: 0.7265 - val_acc: 0.6226\n",
      "Epoch 444/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.4916 - acc: 0.7547 - val_loss: 0.7052 - val_acc: 0.6415\n",
      "Epoch 445/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.4696 - acc: 0.7358 - val_loss: 0.7096 - val_acc: 0.6415\n",
      "Epoch 446/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4592 - acc: 0.6981 - val_loss: 0.7083 - val_acc: 0.6415\n",
      "Epoch 447/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4501 - acc: 0.6981 - val_loss: 0.6974 - val_acc: 0.6792\n",
      "Epoch 448/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4466 - acc: 0.7736 - val_loss: 0.7055 - val_acc: 0.6981\n",
      "Epoch 449/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4503 - acc: 0.7547 - val_loss: 0.7004 - val_acc: 0.6792\n",
      "Epoch 450/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4435 - acc: 0.7547 - val_loss: 0.6994 - val_acc: 0.6415\n",
      "Epoch 451/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4466 - acc: 0.7358 - val_loss: 0.6991 - val_acc: 0.6604\n",
      "Epoch 452/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4495 - acc: 0.7736 - val_loss: 0.7064 - val_acc: 0.6981\n",
      "Epoch 453/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4420 - acc: 0.7547 - val_loss: 0.7053 - val_acc: 0.6604\n",
      "Epoch 454/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4324 - acc: 0.7547 - val_loss: 0.7277 - val_acc: 0.6415\n",
      "Epoch 455/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.5369 - acc: 0.6981 - val_loss: 0.7309 - val_acc: 0.6415\n",
      "Epoch 456/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4716 - acc: 0.6981 - val_loss: 0.7542 - val_acc: 0.6226\n",
      "Epoch 457/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4880 - acc: 0.7547 - val_loss: 0.7447 - val_acc: 0.6226\n",
      "Epoch 458/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4597 - acc: 0.7736 - val_loss: 0.7096 - val_acc: 0.6604\n",
      "Epoch 459/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4397 - acc: 0.7547 - val_loss: 0.7595 - val_acc: 0.6415\n",
      "Epoch 460/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4789 - acc: 0.7170 - val_loss: 0.7301 - val_acc: 0.6415\n",
      "Epoch 461/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4389 - acc: 0.7170 - val_loss: 0.7136 - val_acc: 0.6981\n",
      "Epoch 462/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4357 - acc: 0.7736 - val_loss: 0.7399 - val_acc: 0.6226\n",
      "Epoch 463/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4680 - acc: 0.7547 - val_loss: 0.7260 - val_acc: 0.6415\n",
      "Epoch 464/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4455 - acc: 0.7547 - val_loss: 0.7151 - val_acc: 0.6415\n",
      "Epoch 465/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4451 - acc: 0.6981 - val_loss: 0.7310 - val_acc: 0.6415\n",
      "Epoch 466/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4427 - acc: 0.7170 - val_loss: 0.7233 - val_acc: 0.6415\n",
      "Epoch 467/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4296 - acc: 0.7547 - val_loss: 0.7278 - val_acc: 0.6792\n",
      "Epoch 468/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4371 - acc: 0.7925 - val_loss: 0.7350 - val_acc: 0.6226\n",
      "Epoch 469/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4451 - acc: 0.7736 - val_loss: 0.7308 - val_acc: 0.6981\n",
      "Epoch 470/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4243 - acc: 0.7358 - val_loss: 0.7478 - val_acc: 0.6226\n",
      "Epoch 471/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4513 - acc: 0.6981 - val_loss: 0.7617 - val_acc: 0.6415\n",
      "Epoch 472/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4444 - acc: 0.7358 - val_loss: 0.7395 - val_acc: 0.6792\n",
      "Epoch 473/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4359 - acc: 0.7547 - val_loss: 0.7491 - val_acc: 0.6226\n",
      "Epoch 474/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4372 - acc: 0.7736 - val_loss: 0.7440 - val_acc: 0.6981\n",
      "Epoch 475/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4440 - acc: 0.7547 - val_loss: 0.7523 - val_acc: 0.6226\n",
      "Epoch 476/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.4320 - acc: 0.7547 - val_loss: 0.7466 - val_acc: 0.6604\n",
      "Epoch 477/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4257 - acc: 0.7736 - val_loss: 0.7493 - val_acc: 0.6792\n",
      "Epoch 478/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4280 - acc: 0.7736 - val_loss: 0.7481 - val_acc: 0.6415\n",
      "Epoch 479/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4268 - acc: 0.7736 - val_loss: 0.7442 - val_acc: 0.6792\n",
      "Epoch 480/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4283 - acc: 0.7547 - val_loss: 0.7517 - val_acc: 0.6226\n",
      "Epoch 481/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4336 - acc: 0.7547 - val_loss: 0.7463 - val_acc: 0.6604\n",
      "Epoch 482/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4233 - acc: 0.7547 - val_loss: 0.7506 - val_acc: 0.6792\n",
      "Epoch 483/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4220 - acc: 0.7736 - val_loss: 0.7537 - val_acc: 0.6604\n",
      "Epoch 484/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.4198 - acc: 0.7925 - val_loss: 0.7576 - val_acc: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4222 - acc: 0.7925 - val_loss: 0.7518 - val_acc: 0.6792\n",
      "Epoch 486/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4181 - acc: 0.7925 - val_loss: 0.7540 - val_acc: 0.6792\n",
      "Epoch 487/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4174 - acc: 0.7925 - val_loss: 0.7532 - val_acc: 0.6792\n",
      "Epoch 488/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4166 - acc: 0.7736 - val_loss: 0.7548 - val_acc: 0.6792\n",
      "Epoch 489/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4147 - acc: 0.7736 - val_loss: 0.7576 - val_acc: 0.6604\n",
      "Epoch 490/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4154 - acc: 0.7736 - val_loss: 0.7628 - val_acc: 0.6604\n",
      "Epoch 491/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4189 - acc: 0.7736 - val_loss: 0.7671 - val_acc: 0.6792\n",
      "Epoch 492/800\n",
      "53/53 [==============================] - 0s 244us/step - loss: 0.4132 - acc: 0.7925 - val_loss: 0.7738 - val_acc: 0.6792\n",
      "Epoch 493/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4186 - acc: 0.7736 - val_loss: 0.7818 - val_acc: 0.6415\n",
      "Epoch 494/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.4115 - acc: 0.7925 - val_loss: 0.8016 - val_acc: 0.6226\n",
      "Epoch 495/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.4273 - acc: 0.7736 - val_loss: 0.7953 - val_acc: 0.6226\n",
      "Epoch 496/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4062 - acc: 0.7736 - val_loss: 0.7887 - val_acc: 0.6226\n",
      "Epoch 497/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4319 - acc: 0.7736 - val_loss: 0.8065 - val_acc: 0.6226\n",
      "Epoch 498/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4314 - acc: 0.7547 - val_loss: 0.7810 - val_acc: 0.6604\n",
      "Epoch 499/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4403 - acc: 0.7736 - val_loss: 0.8175 - val_acc: 0.6226\n",
      "Epoch 500/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4302 - acc: 0.7358 - val_loss: 0.7816 - val_acc: 0.6792\n",
      "Epoch 501/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4300 - acc: 0.7170 - val_loss: 0.8020 - val_acc: 0.6226\n",
      "Epoch 502/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4255 - acc: 0.7736 - val_loss: 0.7812 - val_acc: 0.6792\n",
      "Epoch 503/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4136 - acc: 0.7736 - val_loss: 0.7935 - val_acc: 0.6226\n",
      "Epoch 504/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4202 - acc: 0.7925 - val_loss: 0.7862 - val_acc: 0.6415\n",
      "Epoch 505/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4027 - acc: 0.8113 - val_loss: 0.7910 - val_acc: 0.6226\n",
      "Epoch 506/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4198 - acc: 0.8113 - val_loss: 0.8117 - val_acc: 0.6415\n",
      "Epoch 507/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.4210 - acc: 0.7736 - val_loss: 0.7947 - val_acc: 0.6415\n",
      "Epoch 508/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4054 - acc: 0.7925 - val_loss: 0.8142 - val_acc: 0.6226\n",
      "Epoch 509/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4214 - acc: 0.7925 - val_loss: 0.8072 - val_acc: 0.6415\n",
      "Epoch 510/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4232 - acc: 0.7925 - val_loss: 0.8137 - val_acc: 0.6415\n",
      "Epoch 511/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.4176 - acc: 0.7736 - val_loss: 0.8075 - val_acc: 0.6415\n",
      "Epoch 512/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3980 - acc: 0.8113 - val_loss: 0.8180 - val_acc: 0.6226\n",
      "Epoch 513/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4114 - acc: 0.7925 - val_loss: 0.8231 - val_acc: 0.6226\n",
      "Epoch 514/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.4224 - acc: 0.7547 - val_loss: 0.8066 - val_acc: 0.6792\n",
      "Epoch 515/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4007 - acc: 0.7925 - val_loss: 0.8144 - val_acc: 0.6415\n",
      "Epoch 516/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4089 - acc: 0.7925 - val_loss: 0.8159 - val_acc: 0.6604\n",
      "Epoch 517/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3928 - acc: 0.7925 - val_loss: 0.8371 - val_acc: 0.6226\n",
      "Epoch 518/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4091 - acc: 0.8302 - val_loss: 0.8402 - val_acc: 0.6226\n",
      "Epoch 519/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.4091 - acc: 0.8302 - val_loss: 0.8282 - val_acc: 0.6415\n",
      "Epoch 520/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3964 - acc: 0.8113 - val_loss: 0.8307 - val_acc: 0.6792\n",
      "Epoch 521/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3996 - acc: 0.8113 - val_loss: 0.8370 - val_acc: 0.6415\n",
      "Epoch 522/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3971 - acc: 0.8302 - val_loss: 0.8428 - val_acc: 0.6604\n",
      "Epoch 523/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3918 - acc: 0.7925 - val_loss: 0.8467 - val_acc: 0.6415\n",
      "Epoch 524/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3922 - acc: 0.7925 - val_loss: 0.8504 - val_acc: 0.6415\n",
      "Epoch 525/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3949 - acc: 0.8113 - val_loss: 0.8431 - val_acc: 0.6415\n",
      "Epoch 526/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3909 - acc: 0.7925 - val_loss: 0.8456 - val_acc: 0.6415\n",
      "Epoch 527/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3938 - acc: 0.7925 - val_loss: 0.8564 - val_acc: 0.6415\n",
      "Epoch 528/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3893 - acc: 0.8302 - val_loss: 0.8623 - val_acc: 0.6415\n",
      "Epoch 529/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.3867 - acc: 0.8302 - val_loss: 0.8686 - val_acc: 0.6415\n",
      "Epoch 530/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3919 - acc: 0.7925 - val_loss: 0.8686 - val_acc: 0.6415\n",
      "Epoch 531/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3931 - acc: 0.7925 - val_loss: 0.8693 - val_acc: 0.6415\n",
      "Epoch 532/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3856 - acc: 0.7925 - val_loss: 0.8709 - val_acc: 0.6226\n",
      "Epoch 533/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4088 - acc: 0.8113 - val_loss: 0.8870 - val_acc: 0.6415\n",
      "Epoch 534/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3945 - acc: 0.7547 - val_loss: 0.8781 - val_acc: 0.6415\n",
      "Epoch 535/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4156 - acc: 0.7736 - val_loss: 0.8944 - val_acc: 0.6226\n",
      "Epoch 536/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4226 - acc: 0.8491 - val_loss: 0.8850 - val_acc: 0.6415\n",
      "Epoch 537/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3916 - acc: 0.8113 - val_loss: 0.8830 - val_acc: 0.6226\n",
      "Epoch 538/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3819 - acc: 0.8491 - val_loss: 0.8924 - val_acc: 0.6415\n",
      "Epoch 539/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3793 - acc: 0.8302 - val_loss: 0.9047 - val_acc: 0.6038\n",
      "Epoch 540/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3877 - acc: 0.8302 - val_loss: 0.9021 - val_acc: 0.6415\n",
      "Epoch 541/800\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.3864 - acc: 0.8113 - val_loss: 0.8925 - val_acc: 0.6792\n",
      "Epoch 542/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.4010 - acc: 0.8113 - val_loss: 0.8918 - val_acc: 0.6415\n",
      "Epoch 543/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3786 - acc: 0.8679 - val_loss: 0.8913 - val_acc: 0.6604\n",
      "Epoch 544/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3784 - acc: 0.8679 - val_loss: 0.8936 - val_acc: 0.6226\n",
      "Epoch 545/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3799 - acc: 0.8302 - val_loss: 0.8971 - val_acc: 0.6415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 546/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3889 - acc: 0.8113 - val_loss: 0.9074 - val_acc: 0.6415\n",
      "Epoch 547/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3757 - acc: 0.8302 - val_loss: 0.9038 - val_acc: 0.6226\n",
      "Epoch 548/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3771 - acc: 0.8302 - val_loss: 0.9064 - val_acc: 0.6226\n",
      "Epoch 549/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3852 - acc: 0.7925 - val_loss: 0.9075 - val_acc: 0.6415\n",
      "Epoch 550/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3681 - acc: 0.8302 - val_loss: 0.9423 - val_acc: 0.6226\n",
      "Epoch 551/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.4017 - acc: 0.8113 - val_loss: 0.9314 - val_acc: 0.6038\n",
      "Epoch 552/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3737 - acc: 0.8679 - val_loss: 0.9293 - val_acc: 0.6226\n",
      "Epoch 553/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.4233 - acc: 0.750 - 0s 301us/step - loss: 0.3956 - acc: 0.7736 - val_loss: 0.9225 - val_acc: 0.6226\n",
      "Epoch 554/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3758 - acc: 0.8491 - val_loss: 0.9343 - val_acc: 0.6038\n",
      "Epoch 555/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3810 - acc: 0.8302 - val_loss: 0.9385 - val_acc: 0.6038\n",
      "Epoch 556/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3803 - acc: 0.8302 - val_loss: 0.9245 - val_acc: 0.6415\n",
      "Epoch 557/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3676 - acc: 0.8302 - val_loss: 0.9363 - val_acc: 0.6415\n",
      "Epoch 558/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3915 - acc: 0.7925 - val_loss: 0.9204 - val_acc: 0.6415\n",
      "Epoch 559/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3640 - acc: 0.8491 - val_loss: 0.9333 - val_acc: 0.6038\n",
      "Epoch 560/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3754 - acc: 0.8302 - val_loss: 0.9432 - val_acc: 0.6038\n",
      "Epoch 561/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3824 - acc: 0.8302 - val_loss: 0.9280 - val_acc: 0.6415\n",
      "Epoch 562/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3657 - acc: 0.8491 - val_loss: 0.9315 - val_acc: 0.6604\n",
      "Epoch 563/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3667 - acc: 0.8491 - val_loss: 0.9338 - val_acc: 0.6415\n",
      "Epoch 564/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3649 - acc: 0.8491 - val_loss: 0.9387 - val_acc: 0.6415\n",
      "Epoch 565/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3672 - acc: 0.8491 - val_loss: 0.9326 - val_acc: 0.6415\n",
      "Epoch 566/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3633 - acc: 0.8302 - val_loss: 0.9404 - val_acc: 0.6415\n",
      "Epoch 567/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3778 - acc: 0.8113 - val_loss: 0.9481 - val_acc: 0.6415\n",
      "Epoch 568/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3847 - acc: 0.8491 - val_loss: 0.9741 - val_acc: 0.6038\n",
      "Epoch 569/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3806 - acc: 0.8302 - val_loss: 0.9427 - val_acc: 0.6604\n",
      "Epoch 570/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3656 - acc: 0.7925 - val_loss: 0.9466 - val_acc: 0.6226\n",
      "Epoch 571/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.4014 - acc: 0.7736 - val_loss: 0.9436 - val_acc: 0.6604\n",
      "Epoch 572/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3582 - acc: 0.8679 - val_loss: 0.9423 - val_acc: 0.6415\n",
      "Epoch 573/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3595 - acc: 0.8302 - val_loss: 0.9443 - val_acc: 0.6415\n",
      "Epoch 574/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3721 - acc: 0.8302 - val_loss: 0.9531 - val_acc: 0.6415\n",
      "Epoch 575/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3624 - acc: 0.8302 - val_loss: 0.9567 - val_acc: 0.6038\n",
      "Epoch 576/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3618 - acc: 0.875 - 0s 301us/step - loss: 0.3638 - acc: 0.8302 - val_loss: 0.9546 - val_acc: 0.6226\n",
      "Epoch 577/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3577 - acc: 0.8302 - val_loss: 0.9631 - val_acc: 0.6226\n",
      "Epoch 578/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3658 - acc: 0.8491 - val_loss: 0.9597 - val_acc: 0.6415\n",
      "Epoch 579/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3549 - acc: 0.8491 - val_loss: 0.9656 - val_acc: 0.6226\n",
      "Epoch 580/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3850 - acc: 0.8113 - val_loss: 0.9690 - val_acc: 0.6226\n",
      "Epoch 581/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3920 - acc: 0.7925 - val_loss: 0.9854 - val_acc: 0.6038\n",
      "Epoch 582/800\n",
      "53/53 [==============================] - 0s 283us/step - loss: 0.3725 - acc: 0.8302 - val_loss: 0.9709 - val_acc: 0.6415\n",
      "Epoch 583/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3568 - acc: 0.8491 - val_loss: 0.9712 - val_acc: 0.6415\n",
      "Epoch 584/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3545 - acc: 0.8491 - val_loss: 0.9761 - val_acc: 0.6604\n",
      "Epoch 585/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3621 - acc: 0.8302 - val_loss: 0.9804 - val_acc: 0.6415\n",
      "Epoch 586/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3472 - acc: 0.8491 - val_loss: 0.9981 - val_acc: 0.6038\n",
      "Epoch 587/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3755 - acc: 0.8113 - val_loss: 0.9883 - val_acc: 0.6226\n",
      "Epoch 588/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3469 - acc: 0.8491 - val_loss: 0.9836 - val_acc: 0.6415\n",
      "Epoch 589/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3772 - acc: 0.7925 - val_loss: 0.9920 - val_acc: 0.6226\n",
      "Epoch 590/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3683 - acc: 0.8113 - val_loss: 0.9886 - val_acc: 0.6415\n",
      "Epoch 591/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3724 - acc: 0.7925 - val_loss: 1.0417 - val_acc: 0.6038\n",
      "Epoch 592/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3920 - acc: 0.8113 - val_loss: 0.9975 - val_acc: 0.6415\n",
      "Epoch 593/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3569 - acc: 0.8302 - val_loss: 1.0171 - val_acc: 0.6038\n",
      "Epoch 594/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4063 - acc: 0.7736 - val_loss: 0.9950 - val_acc: 0.6604\n",
      "Epoch 595/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3484 - acc: 0.8868 - val_loss: 1.0430 - val_acc: 0.6038\n",
      "Epoch 596/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.4116 - acc: 0.7736 - val_loss: 0.9938 - val_acc: 0.6038\n",
      "Epoch 597/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3428 - acc: 0.8679 - val_loss: 0.9798 - val_acc: 0.6226\n",
      "Epoch 598/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3874 - acc: 0.8113 - val_loss: 1.0001 - val_acc: 0.6038\n",
      "Epoch 599/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3957 - acc: 0.7925 - val_loss: 0.9612 - val_acc: 0.6415\n",
      "Epoch 600/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3483 - acc: 0.8113 - val_loss: 0.9945 - val_acc: 0.6038\n",
      "Epoch 601/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3757 - acc: 0.8113 - val_loss: 0.9651 - val_acc: 0.6415\n",
      "Epoch 602/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3429 - acc: 0.8302 - val_loss: 0.9646 - val_acc: 0.6038\n",
      "Epoch 603/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3580 - acc: 0.8113 - val_loss: 0.9687 - val_acc: 0.6415\n",
      "Epoch 604/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3540 - acc: 0.8302 - val_loss: 0.9688 - val_acc: 0.6415\n",
      "Epoch 605/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3463 - acc: 0.8679 - val_loss: 0.9851 - val_acc: 0.6226\n",
      "Epoch 606/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3484 - acc: 0.8113 - val_loss: 0.9744 - val_acc: 0.6415\n",
      "Epoch 607/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3498 - acc: 0.8491 - val_loss: 0.9777 - val_acc: 0.6226\n",
      "Epoch 608/800\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.3418 - acc: 0.8302 - val_loss: 0.9934 - val_acc: 0.6226\n",
      "Epoch 609/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3428 - acc: 0.8679 - val_loss: 1.0088 - val_acc: 0.6038\n",
      "Epoch 610/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3504 - acc: 0.8491 - val_loss: 0.9967 - val_acc: 0.6415\n",
      "Epoch 611/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3362 - acc: 0.8868 - val_loss: 0.9960 - val_acc: 0.6415\n",
      "Epoch 612/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3446 - acc: 0.8302 - val_loss: 1.0008 - val_acc: 0.6604\n",
      "Epoch 613/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3432 - acc: 0.8491 - val_loss: 1.0104 - val_acc: 0.6415\n",
      "Epoch 614/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3460 - acc: 0.8491 - val_loss: 1.0107 - val_acc: 0.6415\n",
      "Epoch 615/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3384 - acc: 0.875 - 0s 226us/step - loss: 0.3589 - acc: 0.8491 - val_loss: 1.0099 - val_acc: 0.5849\n",
      "Epoch 616/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3420 - acc: 0.8302 - val_loss: 1.0154 - val_acc: 0.6415\n",
      "Epoch 617/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3459 - acc: 0.8491 - val_loss: 1.0298 - val_acc: 0.6226\n",
      "Epoch 618/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3390 - acc: 0.8679 - val_loss: 1.0279 - val_acc: 0.6226\n",
      "Epoch 619/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3614 - acc: 0.812 - 0s 339us/step - loss: 0.3483 - acc: 0.8302 - val_loss: 1.0287 - val_acc: 0.6226\n",
      "Epoch 620/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3329 - acc: 0.8302 - val_loss: 1.0445 - val_acc: 0.6038\n",
      "Epoch 621/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3416 - acc: 0.8491 - val_loss: 1.0439 - val_acc: 0.6038\n",
      "Epoch 622/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3371 - acc: 0.8868 - val_loss: 1.0238 - val_acc: 0.6415\n",
      "Epoch 623/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3400 - acc: 0.8302 - val_loss: 1.0273 - val_acc: 0.5849\n",
      "Epoch 624/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3398 - acc: 0.8302 - val_loss: 1.0309 - val_acc: 0.6415\n",
      "Epoch 625/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3330 - acc: 0.8679 - val_loss: 1.0316 - val_acc: 0.6415\n",
      "Epoch 626/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3312 - acc: 0.8679 - val_loss: 1.0333 - val_acc: 0.6226\n",
      "Epoch 627/800\n",
      "53/53 [==============================] - 0s 264us/step - loss: 0.3314 - acc: 0.8113 - val_loss: 1.0455 - val_acc: 0.5849\n",
      "Epoch 628/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3383 - acc: 0.8113 - val_loss: 1.0530 - val_acc: 0.6415\n",
      "Epoch 629/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3298 - acc: 0.8679 - val_loss: 1.0571 - val_acc: 0.6415\n",
      "Epoch 630/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3451 - acc: 0.8868 - val_loss: 1.0558 - val_acc: 0.6604\n",
      "Epoch 631/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3455 - acc: 0.8302 - val_loss: 1.0670 - val_acc: 0.6226\n",
      "Epoch 632/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3376 - acc: 0.8302 - val_loss: 1.0729 - val_acc: 0.6415\n",
      "Epoch 633/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3271 - acc: 0.8868 - val_loss: 1.0908 - val_acc: 0.6038\n",
      "Epoch 634/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3434 - acc: 0.8491 - val_loss: 1.0714 - val_acc: 0.6226\n",
      "Epoch 635/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3588 - acc: 0.8302 - val_loss: 1.0567 - val_acc: 0.6226\n",
      "Epoch 636/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3407 - acc: 0.8302 - val_loss: 1.0580 - val_acc: 0.6415\n",
      "Epoch 637/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3310 - acc: 0.8491 - val_loss: 1.0553 - val_acc: 0.6038\n",
      "Epoch 638/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3274 - acc: 0.8302 - val_loss: 1.0652 - val_acc: 0.6038\n",
      "Epoch 639/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3246 - acc: 0.8302 - val_loss: 1.0746 - val_acc: 0.6415\n",
      "Epoch 640/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3235 - acc: 0.8302 - val_loss: 1.0816 - val_acc: 0.6415\n",
      "Epoch 641/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3423 - acc: 0.8302 - val_loss: 1.0856 - val_acc: 0.6415\n",
      "Epoch 642/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3389 - acc: 0.8491 - val_loss: 1.0857 - val_acc: 0.6038\n",
      "Epoch 643/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3297 - acc: 0.8302 - val_loss: 1.0875 - val_acc: 0.6226\n",
      "Epoch 644/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3211 - acc: 0.8491 - val_loss: 1.1001 - val_acc: 0.6226\n",
      "Epoch 645/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3309 - acc: 0.8491 - val_loss: 1.0824 - val_acc: 0.6415\n",
      "Epoch 646/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3211 - acc: 0.8868 - val_loss: 1.0860 - val_acc: 0.6038\n",
      "Epoch 647/800\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.3221 - acc: 0.8302 - val_loss: 1.0930 - val_acc: 0.6415\n",
      "Epoch 648/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3193 - acc: 0.8302 - val_loss: 1.1050 - val_acc: 0.6415\n",
      "Epoch 649/800\n",
      "53/53 [==============================] - 0s 244us/step - loss: 0.3219 - acc: 0.8679 - val_loss: 1.1053 - val_acc: 0.6415\n",
      "Epoch 650/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3186 - acc: 0.8868 - val_loss: 1.0908 - val_acc: 0.6415\n",
      "Epoch 651/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3242 - acc: 0.8113 - val_loss: 1.0903 - val_acc: 0.6038\n",
      "Epoch 652/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3178 - acc: 0.8302 - val_loss: 1.0969 - val_acc: 0.6415\n",
      "Epoch 653/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3331 - acc: 0.8679 - val_loss: 1.1045 - val_acc: 0.6226\n",
      "Epoch 654/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3207 - acc: 0.8491 - val_loss: 1.1078 - val_acc: 0.6038\n",
      "Epoch 655/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3294 - acc: 0.8302 - val_loss: 1.1095 - val_acc: 0.5660\n",
      "Epoch 656/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3146 - acc: 0.8113 - val_loss: 1.1178 - val_acc: 0.6226\n",
      "Epoch 657/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3287 - acc: 0.8679 - val_loss: 1.1207 - val_acc: 0.6226\n",
      "Epoch 658/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3250 - acc: 0.8491 - val_loss: 1.1007 - val_acc: 0.6038\n",
      "Epoch 659/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3198 - acc: 0.8302 - val_loss: 1.1049 - val_acc: 0.5660\n",
      "Epoch 660/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3306 - acc: 0.8302 - val_loss: 1.1083 - val_acc: 0.6226\n",
      "Epoch 661/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3184 - acc: 0.8868 - val_loss: 1.1508 - val_acc: 0.6226\n",
      "Epoch 662/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3595 - acc: 0.8113 - val_loss: 1.1118 - val_acc: 0.6604\n",
      "Epoch 663/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3051 - acc: 0.8491 - val_loss: 1.1448 - val_acc: 0.5849\n",
      "Epoch 664/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3692 - acc: 0.8113 - val_loss: 1.1092 - val_acc: 0.6226\n",
      "Epoch 665/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3129 - acc: 0.8491 - val_loss: 1.1215 - val_acc: 0.6226\n",
      "Epoch 666/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 207us/step - loss: 0.3561 - acc: 0.8302 - val_loss: 1.1485 - val_acc: 0.6226\n",
      "Epoch 667/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3696 - acc: 0.8113 - val_loss: 1.1191 - val_acc: 0.6038\n",
      "Epoch 668/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3219 - acc: 0.8113 - val_loss: 1.1322 - val_acc: 0.6038\n",
      "Epoch 669/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3304 - acc: 0.8113 - val_loss: 1.1148 - val_acc: 0.6038\n",
      "Epoch 670/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3058 - acc: 0.8491 - val_loss: 1.1473 - val_acc: 0.6226\n",
      "Epoch 671/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3472 - acc: 0.8491 - val_loss: 1.1261 - val_acc: 0.6226\n",
      "Epoch 672/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3158 - acc: 0.8679 - val_loss: 1.1318 - val_acc: 0.6038\n",
      "Epoch 673/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3435 - acc: 0.8113 - val_loss: 1.1125 - val_acc: 0.5660\n",
      "Epoch 674/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3074 - acc: 0.8491 - val_loss: 1.1244 - val_acc: 0.6226\n",
      "Epoch 675/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3323 - acc: 0.8491 - val_loss: 1.1277 - val_acc: 0.6226\n",
      "Epoch 676/800\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.3294 - acc: 0.8679 - val_loss: 1.1087 - val_acc: 0.5849\n",
      "Epoch 677/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3119 - acc: 0.8113 - val_loss: 1.1219 - val_acc: 0.6038\n",
      "Epoch 678/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3158 - acc: 0.8302 - val_loss: 1.1225 - val_acc: 0.5849\n",
      "Epoch 679/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3062 - acc: 0.8113 - val_loss: 1.1303 - val_acc: 0.6226\n",
      "Epoch 680/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3175 - acc: 0.8679 - val_loss: 1.1308 - val_acc: 0.6226\n",
      "Epoch 681/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3094 - acc: 0.8491 - val_loss: 1.1202 - val_acc: 0.6415\n",
      "Epoch 682/800\n",
      "53/53 [==============================] - 0s 338us/step - loss: 0.3025 - acc: 0.8491 - val_loss: 1.1176 - val_acc: 0.6038\n",
      "Epoch 683/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3062 - acc: 0.8302 - val_loss: 1.1200 - val_acc: 0.6038\n",
      "Epoch 684/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3038 - acc: 0.8302 - val_loss: 1.1299 - val_acc: 0.6415\n",
      "Epoch 685/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.3042 - acc: 0.8491 - val_loss: 1.1417 - val_acc: 0.6415\n",
      "Epoch 686/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3065 - acc: 0.8679 - val_loss: 1.1435 - val_acc: 0.5849\n",
      "Epoch 687/800\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.3025 - acc: 0.8491 - val_loss: 1.1426 - val_acc: 0.6038\n",
      "Epoch 688/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3065 - acc: 0.8679 - val_loss: 1.1434 - val_acc: 0.6415\n",
      "Epoch 689/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3048 - acc: 0.8679 - val_loss: 1.1449 - val_acc: 0.6226\n",
      "Epoch 690/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3130 - acc: 0.8491 - val_loss: 1.1584 - val_acc: 0.6038\n",
      "Epoch 691/800\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.3032 - acc: 0.8491 - val_loss: 1.1556 - val_acc: 0.6415\n",
      "Epoch 692/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2976 - acc: 0.8679 - val_loss: 1.1658 - val_acc: 0.6415\n",
      "Epoch 693/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3081 - acc: 0.8679 - val_loss: 1.1577 - val_acc: 0.6415\n",
      "Epoch 694/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2953 - acc: 0.8679 - val_loss: 1.1653 - val_acc: 0.5849\n",
      "Epoch 695/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3023 - acc: 0.8302 - val_loss: 1.1746 - val_acc: 0.6038\n",
      "Epoch 696/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3011 - acc: 0.8302 - val_loss: 1.1652 - val_acc: 0.6415\n",
      "Epoch 697/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3069 - acc: 0.8679 - val_loss: 1.1753 - val_acc: 0.6226\n",
      "Epoch 698/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3024 - acc: 0.8679 - val_loss: 1.1715 - val_acc: 0.6038\n",
      "Epoch 699/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3056 - acc: 0.8302 - val_loss: 1.2067 - val_acc: 0.5849\n",
      "Epoch 700/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3181 - acc: 0.8113 - val_loss: 1.1854 - val_acc: 0.6038\n",
      "Epoch 701/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3075 - acc: 0.8491 - val_loss: 1.2008 - val_acc: 0.6415\n",
      "Epoch 702/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3049 - acc: 0.8679 - val_loss: 1.1767 - val_acc: 0.6226\n",
      "Epoch 703/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2951 - acc: 0.8679 - val_loss: 1.1800 - val_acc: 0.5849\n",
      "Epoch 704/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3052 - acc: 0.8113 - val_loss: 1.1708 - val_acc: 0.6038\n",
      "Epoch 705/800\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.3143 - acc: 0.8491 - val_loss: 1.1754 - val_acc: 0.6226\n",
      "Epoch 706/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.3017 - acc: 0.8868 - val_loss: 1.1744 - val_acc: 0.6226\n",
      "Epoch 707/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3036 - acc: 0.8491 - val_loss: 1.2014 - val_acc: 0.6226\n",
      "Epoch 708/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3046 - acc: 0.8302 - val_loss: 1.1968 - val_acc: 0.6604\n",
      "Epoch 709/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3091 - acc: 0.8868 - val_loss: 1.2180 - val_acc: 0.6226\n",
      "Epoch 710/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.2370 - acc: 0.906 - 0s 207us/step - loss: 0.3080 - acc: 0.8491 - val_loss: 1.1919 - val_acc: 0.6226\n",
      "Epoch 711/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2950 - acc: 0.8679 - val_loss: 1.1862 - val_acc: 0.5660\n",
      "Epoch 712/800\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.3034 - acc: 0.8679 - val_loss: 1.1731 - val_acc: 0.6226\n",
      "Epoch 713/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.3004 - acc: 0.8679 - val_loss: 1.1733 - val_acc: 0.6226\n",
      "Epoch 714/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2986 - acc: 0.8679 - val_loss: 1.1792 - val_acc: 0.6038\n",
      "Epoch 715/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2984 - acc: 0.8679 - val_loss: 1.1791 - val_acc: 0.6415\n",
      "Epoch 716/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3089 - acc: 0.8679 - val_loss: 1.1955 - val_acc: 0.5849\n",
      "Epoch 717/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3159 - acc: 0.8491 - val_loss: 1.2071 - val_acc: 0.6604\n",
      "Epoch 718/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2900 - acc: 0.8679 - val_loss: 1.2137 - val_acc: 0.6226\n",
      "Epoch 719/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.3016 - acc: 0.8302 - val_loss: 1.2139 - val_acc: 0.6038\n",
      "Epoch 720/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2958 - acc: 0.8679 - val_loss: 1.2144 - val_acc: 0.6226\n",
      "Epoch 721/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2943 - acc: 0.8868 - val_loss: 1.2108 - val_acc: 0.6038\n",
      "Epoch 722/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.2908 - acc: 0.8302 - val_loss: 1.2329 - val_acc: 0.5849\n",
      "Epoch 723/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2966 - acc: 0.8302 - val_loss: 1.2210 - val_acc: 0.6038\n",
      "Epoch 724/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2822 - acc: 0.8679 - val_loss: 1.2285 - val_acc: 0.6226\n",
      "Epoch 725/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3142 - acc: 0.8302 - val_loss: 1.2349 - val_acc: 0.6226\n",
      "Epoch 726/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.3007 - acc: 0.8679 - val_loss: 1.2442 - val_acc: 0.5849\n",
      "Epoch 727/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.3008 - acc: 0.8302 - val_loss: 1.2416 - val_acc: 0.5849\n",
      "Epoch 728/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2930 - acc: 0.8302 - val_loss: 1.2348 - val_acc: 0.6415\n",
      "Epoch 729/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2950 - acc: 0.8491 - val_loss: 1.2329 - val_acc: 0.6604\n",
      "Epoch 730/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2844 - acc: 0.8491 - val_loss: 1.2328 - val_acc: 0.6038\n",
      "Epoch 731/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3261 - acc: 0.812 - 0s 207us/step - loss: 0.2911 - acc: 0.8491 - val_loss: 1.2420 - val_acc: 0.6038\n",
      "Epoch 732/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.3008 - acc: 0.8302 - val_loss: 1.2409 - val_acc: 0.6038\n",
      "Epoch 733/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2906 - acc: 0.8302 - val_loss: 1.2366 - val_acc: 0.5849\n",
      "Epoch 734/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2803 - acc: 0.8491 - val_loss: 1.2454 - val_acc: 0.6226\n",
      "Epoch 735/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.2927 - acc: 0.9057 - val_loss: 1.2626 - val_acc: 0.6226\n",
      "Epoch 736/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2934 - acc: 0.8491 - val_loss: 1.2508 - val_acc: 0.6038\n",
      "Epoch 737/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2916 - acc: 0.8679 - val_loss: 1.2765 - val_acc: 0.5849\n",
      "Epoch 738/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2953 - acc: 0.8302 - val_loss: 1.2523 - val_acc: 0.6226\n",
      "Epoch 739/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2789 - acc: 0.8679 - val_loss: 1.2623 - val_acc: 0.6415\n",
      "Epoch 740/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2942 - acc: 0.8491 - val_loss: 1.2488 - val_acc: 0.6415\n",
      "Epoch 741/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2924 - acc: 0.8679 - val_loss: 1.2468 - val_acc: 0.5849\n",
      "Epoch 742/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2887 - acc: 0.8491 - val_loss: 1.2432 - val_acc: 0.5849\n",
      "Epoch 743/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2829 - acc: 0.8491 - val_loss: 1.2507 - val_acc: 0.6038\n",
      "Epoch 744/800\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.3558 - acc: 0.812 - 0s 320us/step - loss: 0.2851 - acc: 0.8491 - val_loss: 1.2626 - val_acc: 0.6038\n",
      "Epoch 745/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2821 - acc: 0.8491 - val_loss: 1.2533 - val_acc: 0.6038\n",
      "Epoch 746/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2829 - acc: 0.8679 - val_loss: 1.2587 - val_acc: 0.6604\n",
      "Epoch 747/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2812 - acc: 0.8679 - val_loss: 1.2575 - val_acc: 0.6415\n",
      "Epoch 748/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2841 - acc: 0.8868 - val_loss: 1.2549 - val_acc: 0.6038\n",
      "Epoch 749/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2778 - acc: 0.8679 - val_loss: 1.2595 - val_acc: 0.6038\n",
      "Epoch 750/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2800 - acc: 0.8679 - val_loss: 1.2697 - val_acc: 0.5849\n",
      "Epoch 751/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2775 - acc: 0.8491 - val_loss: 1.2704 - val_acc: 0.6226\n",
      "Epoch 752/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2767 - acc: 0.8679 - val_loss: 1.2702 - val_acc: 0.6226\n",
      "Epoch 753/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3052 - acc: 0.8491 - val_loss: 1.2660 - val_acc: 0.6038\n",
      "Epoch 754/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2767 - acc: 0.8679 - val_loss: 1.2919 - val_acc: 0.5849\n",
      "Epoch 755/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2928 - acc: 0.8302 - val_loss: 1.2709 - val_acc: 0.5849\n",
      "Epoch 756/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2907 - acc: 0.8491 - val_loss: 1.2837 - val_acc: 0.6415\n",
      "Epoch 757/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2865 - acc: 0.8679 - val_loss: 1.2741 - val_acc: 0.6038\n",
      "Epoch 758/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.2833 - acc: 0.8491 - val_loss: 1.2876 - val_acc: 0.6038\n",
      "Epoch 759/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2774 - acc: 0.8679 - val_loss: 1.2852 - val_acc: 0.6226\n",
      "Epoch 760/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2808 - acc: 0.8679 - val_loss: 1.2949 - val_acc: 0.6226\n",
      "Epoch 761/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2815 - acc: 0.8679 - val_loss: 1.2812 - val_acc: 0.6226\n",
      "Epoch 762/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2710 - acc: 0.8679 - val_loss: 1.3022 - val_acc: 0.6038\n",
      "Epoch 763/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2925 - acc: 0.8302 - val_loss: 1.3099 - val_acc: 0.5849\n",
      "Epoch 764/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2785 - acc: 0.8302 - val_loss: 1.3003 - val_acc: 0.6226\n",
      "Epoch 765/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2825 - acc: 0.8868 - val_loss: 1.3150 - val_acc: 0.6226\n",
      "Epoch 766/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2868 - acc: 0.8491 - val_loss: 1.2972 - val_acc: 0.6226\n",
      "Epoch 767/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2700 - acc: 0.8679 - val_loss: 1.3128 - val_acc: 0.5660\n",
      "Epoch 768/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2834 - acc: 0.8491 - val_loss: 1.3090 - val_acc: 0.6038\n",
      "Epoch 769/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2715 - acc: 0.8491 - val_loss: 1.3157 - val_acc: 0.6038\n",
      "Epoch 770/800\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.2916 - acc: 0.8679 - val_loss: 1.3268 - val_acc: 0.6415\n",
      "Epoch 771/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2827 - acc: 0.8679 - val_loss: 1.3174 - val_acc: 0.5849\n",
      "Epoch 772/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.3189 - acc: 0.8679 - val_loss: 1.3511 - val_acc: 0.5849\n",
      "Epoch 773/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2974 - acc: 0.8491 - val_loss: 1.3019 - val_acc: 0.6415\n",
      "Epoch 774/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3180 - acc: 0.8679 - val_loss: 1.3486 - val_acc: 0.6226\n",
      "Epoch 775/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3020 - acc: 0.8491 - val_loss: 1.3039 - val_acc: 0.6226\n",
      "Epoch 776/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3024 - acc: 0.8491 - val_loss: 1.3853 - val_acc: 0.5472\n",
      "Epoch 777/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.3249 - acc: 0.8302 - val_loss: 1.3184 - val_acc: 0.6038\n",
      "Epoch 778/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2978 - acc: 0.8868 - val_loss: 1.3191 - val_acc: 0.6415\n",
      "Epoch 779/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2919 - acc: 0.8491 - val_loss: 1.2822 - val_acc: 0.6226\n",
      "Epoch 780/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2685 - acc: 0.8679 - val_loss: 1.2883 - val_acc: 0.5660\n",
      "Epoch 781/800\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.2974 - acc: 0.8491 - val_loss: 1.2795 - val_acc: 0.5849\n",
      "Epoch 782/800\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.2688 - acc: 0.8679 - val_loss: 1.2818 - val_acc: 0.6415\n",
      "Epoch 783/800\n",
      "53/53 [==============================] - 0s 169us/step - loss: 0.3008 - acc: 0.8491 - val_loss: 1.2918 - val_acc: 0.6415\n",
      "Epoch 784/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2759 - acc: 0.8491 - val_loss: 1.2962 - val_acc: 0.5849\n",
      "Epoch 785/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2756 - acc: 0.8679 - val_loss: 1.3378 - val_acc: 0.5849\n",
      "Epoch 786/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 169us/step - loss: 0.2976 - acc: 0.8113 - val_loss: 1.3093 - val_acc: 0.6038\n",
      "Epoch 787/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2738 - acc: 0.8679 - val_loss: 1.2982 - val_acc: 0.6415\n",
      "Epoch 788/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2807 - acc: 0.8868 - val_loss: 1.2893 - val_acc: 0.6226\n",
      "Epoch 789/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2716 - acc: 0.8679 - val_loss: 1.2981 - val_acc: 0.6038\n",
      "Epoch 790/800\n",
      "53/53 [==============================] - 0s 188us/step - loss: 0.2810 - acc: 0.8868 - val_loss: 1.3385 - val_acc: 0.5660\n",
      "Epoch 791/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.3036 - acc: 0.8302 - val_loss: 1.2936 - val_acc: 0.6038\n",
      "Epoch 792/800\n",
      "53/53 [==============================] - 0s 207us/step - loss: 0.2587 - acc: 0.8491 - val_loss: 1.3108 - val_acc: 0.6415\n",
      "Epoch 793/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2890 - acc: 0.8302 - val_loss: 1.3146 - val_acc: 0.6415\n",
      "Epoch 794/800\n",
      "53/53 [==============================] - 0s 226us/step - loss: 0.2769 - acc: 0.8679 - val_loss: 1.3080 - val_acc: 0.6038\n",
      "Epoch 795/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2689 - acc: 0.8491 - val_loss: 1.3216 - val_acc: 0.6038\n",
      "Epoch 796/800\n",
      "53/53 [==============================] - 0s 245us/step - loss: 0.2881 - acc: 0.8491 - val_loss: 1.2965 - val_acc: 0.6038\n",
      "Epoch 797/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2907 - acc: 0.8302 - val_loss: 1.3170 - val_acc: 0.6415\n",
      "Epoch 798/800\n",
      "53/53 [==============================] - 0s 282us/step - loss: 0.2878 - acc: 0.8491 - val_loss: 1.3083 - val_acc: 0.6415\n",
      "Epoch 799/800\n",
      "53/53 [==============================] - 0s 263us/step - loss: 0.2785 - acc: 0.8491 - val_loss: 1.3260 - val_acc: 0.6038\n",
      "Epoch 800/800\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.2684 - acc: 0.8679 - val_loss: 1.3237 - val_acc: 0.6226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x176f141efd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/_index.ipynb\n",
    "# as a tutorial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(),\n",
    "#   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.fit(np.array(train_inputs), np.array(train_outputs), epochs=5000)\n",
    "model.fit(np.array(train_inputs), np.array(train_outputs), epochs=800,\n",
    "              validation_data=(np.array(test_inputs), np.array(test_outputs)))\n",
    "\n",
    "# model.evaluate(np.array(test_inputs), np.array(test_outputs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
