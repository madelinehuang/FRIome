{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "['male', 'female']\n",
      "Bacilli \n",
      "P-value: 0.040059\n",
      "Fusobacteria \n",
      "P-value: 0.000003\n",
      "Epsilonproteobacteria \n",
      "P-value: 0.021050\n",
      "Alphaproteobacteria \n",
      "P-value: 0.038678\n",
      "Thermotogae \n",
      "P-value: 0.012158\n",
      "\n",
      "\n",
      "106 [[3.9442973119999998, 0.076904877, -0.33510018199999997, -0.342277971, -0.353762432], [3.9723758339999997, 0.190906131, -0.362045826, -0.357471775, -0.381358487], [3.760585735, 0.602311415, -0.370152097, -0.361497044, -0.376256186], [3.114230698, -0.22210792399999998, -0.339227998, -0.318056067, -0.331408263], [5.343307545, 0.134594481, -0.308472788, -0.30015785300000003, -0.319163419], [3.503269346, 0.480379028, -0.363317868, -0.366886806, -0.377593619], [3.746173966, -0.021308512, -0.35812048399999996, -0.329250886, -0.343685685], [2.187348146, -0.207054766, -0.33773129700000004, -0.328490128, -0.336431133], [3.77699665, 0.203021108, -0.31253190000000003, -0.35530704, -0.35530704], [4.293834467, -0.064573619, -0.349397739, -0.333604432, -0.351576126], [4.398598967, 0.094596186, -0.322446842, -0.331351675, -0.340256509], [3.8383945489999998, 0.321829575, -0.36603559999999996, -0.317943331, -0.350004844], [3.724979925, -0.017653774, -0.32017449600000003, -0.339258747, -0.349154285], [1.881491592, -0.07328821599999999, -0.335002537, -0.310231223, -0.331771496], [3.840814983, -0.199437184, -0.304218056, -0.293433896, -0.306585202], [1.4965550280000002, -0.221443492, -0.283463036, -0.28452690399999997, -0.28494063], [4.392055474, -0.227896386, -0.344952994, -0.32477082, -0.344448439], [4.102961625, 0.061294681, -0.354263771, -0.35346153399999997, -0.36950626200000003], [4.810152351, 0.032039231, -0.327297372, -0.31250331600000003, -0.339890659], [4.290586455, -0.050282847, -0.32779715600000003, -0.318488954, -0.324766579], [4.625243086, 0.1392085, -0.26051665, -0.314365634, -0.314365634], [6.050165301, 0.007082015, -0.222611334, -0.22591627399999997, -0.22591627399999997], [1.9172609919999999, 2.499762987, 0.208715175, -0.419081972, -0.42034896899999996], [5.588801677999999, 1.12379524, -0.25670087, -0.333014617, -0.333014617], [4.552835497, 0.886862887, -0.285773846, -0.38792373, -0.38836308399999997], [4.401855623, 0.22495754699999998, -0.357602374, -0.371742178, -0.371742178], [5.916442238999999, 0.18348419800000002, -0.178390952, -0.292479669, -0.292479669], [5.118078409, 0.271119899, -0.289996876, -0.334068396, -0.334068396], [1.851373532, 0.14774790699999998, -0.312282412, -0.333127982, -0.333699094], [4.131283577, -0.122667651, -0.160292556, -0.316634553, -0.31827041899999997], [2.07117524, 0.614806558, -0.331259712, -0.36566212200000003, -0.36566212200000003], [4.476113496, 0.027046855, -0.286148475, -0.323393325, -0.323393325], [2.761264077, 0.738901857, -0.155003094, -0.39476768700000003, -0.397373824], [3.2585512189999997, -0.088814578, -0.187067218, -0.339528211, -0.339528211], [2.110565488, 0.521211499, -0.260882303, -0.315086824, -0.315086824], [5.044392528, 0.772542618, -0.29934212600000004, -0.350834431, -0.351236714], [4.617816033, -0.17615445, -0.238413807, -0.33958526200000005, -0.33958526200000005], [4.834078831999999, 0.36251749899999997, -0.325785268, -0.342542704, -0.342542704], [3.376005192, -0.134533378, -0.237389922, -0.302234265, -0.302234265], [3.035985384, 1.8049423390000001, -0.32379094399999997, -0.360538498, -0.360538498], [5.2300900089999995, 0.026638086000000002, -0.25823080600000003, -0.26971745399999997, -0.26971745399999997], [0.9911095590000001, 0.374093701, -0.028452956, -0.302231085, -0.302231085], [1.4112945909999999, 0.038526165, 0.056565172000000004, -0.278960357, -0.280764258], [4.2482831789999995, 0.229636929, -0.34445539299999994, -0.34445539299999994, -0.34445539299999994], [1.942460482, 0.765748973, -0.269597871, -0.313401007, -0.31539205800000003], [5.749309908, 0.230339715, -0.201260283, -0.30227304899999996, -0.304568793], [4.644884794, 0.011460119, -0.164628701, -0.30054872, -0.30054872], [5.033325436, 0.615967122, -0.284427623, -0.295275752, -0.295275752], [5.641974451, -0.141219033, -0.24354409899999999, -0.259989199, -0.259989199], [2.990797205, -0.22360247600000002, -0.28520724, -0.31669412, -0.318063114], [4.733129215, 0.475901872, -0.281632084, -0.31425995100000004, -0.314496385], [3.687152735, -0.016850384, -0.250629125, -0.34929013299999995, -0.34951798700000003], [1.282338129, 0.47905851, -0.24276176800000002, -0.319695591, -0.319695591], [3.086855263, 0.694054616, -0.13146160699999998, -0.39167867700000003, -0.39167867700000003], [3.714683317, -0.065348679, -0.235985165, -0.39794522, -0.400837364], [4.2527851960000005, 0.51873676, -0.20249999, -0.37232027700000003, -0.37232027700000003], [2.796531556, 0.200459279, -0.17938079, -0.39472319100000003, -0.403695791], [2.377874643, -0.022357451, -0.23635019999999998, -0.378479711, -0.386464515], [5.467952887999999, -0.0098405, -0.262925708, -0.279655069, -0.280084027], [2.652661754, 1.190386213, -0.259744182, -0.41957429999999996, -0.42370364899999996], [5.992142816, -0.049301490999999996, -0.22020719800000002, -0.247122433, -0.24941565899999998], [6.01130172, -0.080100202, -0.20665852199999998, -0.234183864, -0.235785868], [2.041360084, -0.0051922109999999995, -0.16538513400000002, -0.353056406, -0.35890286299999996], [5.156091231, 0.153401384, -0.171448606, -0.25807527, -0.333873601], [5.117264551, -0.116715987, -0.25606421100000004, -0.340477077, -0.34373108799999996], [3.488088813, -0.088017921, -0.26190894600000003, -0.316762637, -0.320140723], [4.155095642, 0.025510566000000002, -0.294082112, -0.366705506, -0.374912945], [4.531074241000001, -0.267905983, -0.310745021, -0.32636867, -0.32863661899999996], [5.325111934, 0.701748521, -0.281102492, -0.347476846, -0.35217948200000004], [1.5749517259999999, 0.256292148, 0.034083981, -0.334339084, -0.33690425700000004], [5.4098890189999995, -0.080578127, -0.25130453399999997, -0.30087568600000003, -0.30356429], [3.590753691, 0.34085651299999997, -0.301186778, -0.39946577299999997, -0.405002618], [1.933252219, 0.241523559, -0.19210862, -0.36330885799999996, -0.375322909], [3.003598447, 0.804077692, -0.068668882, -0.401400917, -0.40638566600000003], [5.615397421, 0.127875741, -0.254753919, -0.300948796, -0.305425044], [4.647735389, 0.615212407, -0.259220217, -0.3455376, -0.39244922200000004], [1.293811962, 1.625695734, -0.304976822, -0.41806509700000005, -0.41938314200000004], [5.5435314920000005, -0.131258965, -0.260009797, -0.304227254, -0.31300572], [3.2537226589999997, -0.080439482, -0.249186617, -0.386996778, -0.388403004], [1.122429726, 1.783913646, -0.20421915899999998, -0.39600164200000004, -0.401523211], [1.30302168, 2.114026069, -0.149858641, -0.396384865, -0.40140138700000005], [1.1275937390000002, 2.7542676719999997, -0.124831876, -0.42196426600000003, -0.42448233700000004], [0.8438910470000001, 2.6500162919999997, -0.229239119, -0.404460224, -0.40961378600000004], [1.09831716, 2.821724623, 0.089839716, -0.41984383700000005, -0.425998864], [1.747345224, 2.116180751, 0.033847726, -0.41315162200000005, -0.435135196], [0.801398092, 2.738849112, 0.20559548600000002, -0.411086919, -0.423711913], [2.124023535, 0.845342287, -0.239250477, -0.34386088, -0.349782224], [1.685317235, 2.081840131, -0.168626652, -0.418356336, -0.426330289], [5.06228035, 0.167428635, -0.307162147, -0.34536819700000004, -0.348950014], [1.912476302, 0.274351713, -0.18506356699999998, -0.30722879, -0.319445312], [3.710497321, -0.00819503, -0.282268683, -0.340330966, -0.34598957799999996], [2.88692173, -0.012497213, -0.258934056, -0.37423621, -0.38215247700000005], [5.319989731000001, 0.021865142, -0.284529362, -0.293005005, -0.296395262], [2.0706874269999997, 0.028919629, -0.22742332199999998, -0.313073815, -0.315812197], [4.359425873999999, 1.0562953240000001, -0.324804735, -0.389721486, -0.392959675], [4.1631193710000005, 1.8821596630000001, -0.248815497, -0.390836264, -0.39526058700000005], [1.18370364, 0.323127874, -0.135006964, -0.315837398, -0.320731005], [2.001065959, -0.19688731399999998, -0.20615413800000001, -0.31255100199999997, -0.315125119], [5.434112297, -0.147455146, -0.184513382, -0.272329106, -0.274963578], [5.6174110939999995, -0.22736438, -0.23297112399999997, -0.253614135, -0.257691766], [1.77685276, 0.8139224829999999, -0.052247151, -0.36411138299999996, -0.36878754799999997], [1.061263764, 0.8636475659999999, 0.296567722, -0.31301382699999997, -0.31686240600000004], [4.043781339, 0.849914885, -0.256873833, -0.402783541, -0.410145958], [3.00516821, 0.14471658099999998, -0.160480076, -0.302905183, -0.309041412], [4.839306407, 0.037633642, -0.216660555, -0.25156368, -0.34630073299999997], [6.15350649, -0.16858921899999998, -0.217564858, -0.222274054, -0.22839600899999998]]\n",
      "categories  1 / 1\n"
     ]
    }
   ],
   "source": [
    "from enum import Enum\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "train_inputs = []\n",
    "train_outputs = []\n",
    "test_inputs = []\n",
    "test_outputs = []\n",
    "\n",
    "#Enum for all the categories and their column number\n",
    "class Col(Enum):\n",
    "    Gender = 1\n",
    "    Menstrual = 2 \n",
    "    SleepPrior = 3 \n",
    "    Prescription = 4 \n",
    "    OralAntibiotics = 5 \n",
    "    TopAntibiotics = 6 \n",
    "    Eyes = 7 \n",
    "    Hands = 8 \n",
    "    Race = 9 \n",
    "    Feeling = 10 \n",
    "    Symptoms = 11 \n",
    "    Facial = 12 \n",
    "    LastVomit = 13 \n",
    "    EnvAllergies = 14 \n",
    "    Snore = 15 \n",
    "    GrindTeeth = 16 \n",
    "    EarInfect = 17 \n",
    "    AllergyTime = 18 \n",
    "    Skin = 19 \n",
    "    OralSurgery = 20 \n",
    "    HeartDisease = 21 \n",
    "    BadTeeth = 22 \n",
    "    EatPrior = 23 \n",
    "    DrinkPrior = 24 \n",
    "    GumDay = 25 \n",
    "    YogurtWeek = 26 \n",
    "    TeaWeek = 27 \n",
    "    CoffeeWeek = 28 \n",
    "    SodaWeek = 29 \n",
    "    FastFoodWeek = 30 \n",
    "    EatOutWeek = 31 \n",
    "    Straw = 32 \n",
    "    AddedSugar = 33 \n",
    "    Spicy = 34 \n",
    "    ShareDrink = 35 \n",
    "    MeatWeek = 36 \n",
    "    FreshWeek = 37 \n",
    "    BrushTongue = 38 \n",
    "    BrushTeethWeek = 39 \n",
    "    TobaccoWeek = 40 \n",
    "    FlossWeek = 41 \n",
    "    DentistYear = 42 \n",
    "    Toothbrush = 43 \n",
    "    Mouthwash = 44 \n",
    "    Toothpaste = 45 \n",
    "    WashHandsEat = 46 \n",
    "    WashHandsRestroom = 47 \n",
    "    ChangeToothbrush = 48 \n",
    "    BiteNails = 49 \n",
    "    OrthoDevice = 50 \n",
    "    Device = 51 \n",
    "    Stress = 52 \n",
    "    HandleStress = 53 \n",
    "    Organized = 54 \n",
    "    RateStress = 55 \n",
    "    AvgSleep = 56 \n",
    "    AvgWork = 57 \n",
    "    Setting = 58 \n",
    "    Environment = 59 \n",
    "    UpDown = 60 \n",
    "    Weight = 61 \n",
    "    ExerciseMonth = 62 \n",
    "    Transportation = 63 \n",
    "    Orientation = 64 \n",
    "    NearDogsWeek = 65 \n",
    "    NearCatsWeek = 66 \n",
    "    ShareBathroom = 67 \n",
    "    BooksYear = 68 \n",
    "    Alarms = 69 \n",
    "    Patience = 70 \n",
    "    Lipstick = 71 \n",
    "    IntroExtro = 72 \n",
    "    Relgious = 73 \n",
    "    OptiPessi = 74 \n",
    "    SexuallyActive = 75 \n",
    "    OralSex = 76 \n",
    "    Music = 77 \n",
    "    AvgGrade = 78 \n",
    "    RateHappy = 79 \n",
    "    Arts = 80 \n",
    "    Kiss = 81 \n",
    "    Roommates = 82 \n",
    "\n",
    "    \n",
    "#Enum for type of test\n",
    "class Test(Enum):\n",
    "    Ttest = 1\n",
    "    Anova = 2\n",
    "    \n",
    "\n",
    "def sleepPrior(category, data):\n",
    "    if category != Col.SleepPrior:\n",
    "        return data\n",
    "    \n",
    "    #if SleepPrior, manipulate the data so that the subcategories don't go over 7\n",
    "    #also create new subcategories to make it more general\n",
    "    data[category.name] = data[category.name].replace(['0', '1', '2', '3'], 'less than 4')\n",
    "    data[category.name] = data[category.name].replace(['4', '5', '6', '7'], '4 to 7')\n",
    "    data[category.name] = data[category.name].replace(['8', '9', '10', '11', '12'], 'more than 7')\n",
    "    return data\n",
    "\n",
    "\n",
    "def prescription(category, data):\n",
    "    if category != Col.Prescription:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that if the prescription column has a specific prescription, replace with yes\n",
    "    data[category.name] = data[category.name].replace(['None', 'none', 'no '], 'no')\n",
    "    data.loc[(data[category.name] != 'no') & (data[category.name] != 'No') & (data[category.name] != 'nan'), \n",
    "             category.name] = 'yes'\n",
    "    return data\n",
    "\n",
    "\n",
    "def eyes(category, data):\n",
    "    if category != Col.Eyes:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data to make it more generic\n",
    "    data[category.name] = data[category.name].replace('Green/blue/gold mix', 'hazel')\n",
    "    return data\n",
    "\n",
    "\n",
    "def perWeek(category, data):\n",
    "    if category not in (Col.TeaWeek, Col.CoffeeWeek, Col.SodaWeek, Col.FastFoodWeek, Col.BrushTeethWeek, \n",
    "                        Col.FlossWeek, Col.BooksYear, Col.GumDay, Col.EatOutWeek, Col.AvgSleep, Col.AvgWork, \n",
    "                        Col.ExerciseMonth) :\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so results don't show as dates\n",
    "    data[category.name] = data[category.name].replace('5-Jan', '1-5')\n",
    "    data[category.name] = data[category.name].replace('10-Jun', '6-10')\n",
    "    data[category.name] = data[category.name].replace('15-Nov', '11-15')\n",
    "    \n",
    "    data[category.name] = data[category.name].replace('2-Jan', '1-2')\n",
    "    data[category.name] = data[category.name].replace('4-Mar', '3-4')\n",
    "    data[category.name] = data[category.name].replace('6-May', '5-6')\n",
    "    data[category.name] = data[category.name].replace('8-Jul', '7-8')\n",
    "    data[category.name] = data[category.name].replace('10-Sep', '9-10')\n",
    "    data[category.name] = data[category.name].replace('12-Nov', '11-12')\n",
    "    \n",
    "    if category == Col.FlossWeek:\n",
    "        data[category.name] = data[category.name].replace('5-Nov', '11-15')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def numToWords(category, data):\n",
    "    if category not in (Col.AddedSugar, Col.Straw, Col.Lipstick):\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so results don't show as dates\n",
    "    data[category.name] = data[category.name].replace('1', 'never')\n",
    "    data[category.name] = data[category.name].replace('2', 'rarely')\n",
    "    data[category.name] = data[category.name].replace('3', 'sometimes')\n",
    "    data[category.name] = data[category.name].replace('4', 'often')\n",
    "    data[category.name] = data[category.name].replace('5', 'always')\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def mouthwash(category, data):\n",
    "    if category != Col.Mouthwash:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that results are in form of yes or no\n",
    "    data.loc[(data[category.name] != 'never') & (data[category.name] != 'No') & (data[category.name] != 'nan'), \n",
    "             category.name] = 'yes'\n",
    "    data[category.name] = data[category.name].replace('never', 'no')\n",
    "    return data\n",
    "\n",
    "\n",
    "def religious(category, data):\n",
    "    if category != Col.Relgious:\n",
    "        return data\n",
    "    \n",
    "    #manipulate the data so that results are in form of yes or no\n",
    "    data.loc[(data[category.name] != 'No') & (data[category.name] != 'nan'), category.name] = 'yes'\n",
    "    data[category.name] = data[category.name].replace('never', 'no')\n",
    "    return data\n",
    "\n",
    "\n",
    "def orientation(category, data):\n",
    "    if category != Col.Orientation:\n",
    "        return data\n",
    "    \n",
    "    #fix spelling mistakes, change bicurious to bisexual to generalize data\n",
    "    data[category.name] = data[category.name].replace('hetrosexual', 'heterosexual')\n",
    "    data[category.name] = data[category.name].replace(['bicurious', 'Bicurious'], 'bisexual')\n",
    "    return data\n",
    "\n",
    "\n",
    "bactClassDict = {}\n",
    "total = 0\n",
    "sumCat = 0\n",
    "    \n",
    "def runTests(data, category, outputMap, showAllClasses):\n",
    "    subcategory = []\n",
    "    categoryDF = []\n",
    "    bactClasses = []\n",
    "    sigClasses = []\n",
    "    inputs = []\n",
    "    global total\n",
    "    global sumCat\n",
    "    \n",
    "    #decided not to do these groups\n",
    "    if category.name in ('Menstrual', 'Race', 'Feeling', 'Symptoms', 'EnvAllergies', 'Skin', 'EatPrior',\n",
    "                        'DrinkPrior', 'TobaccoWeek', 'Toothpaste', 'BiteNails', 'Transportation', 'Environment', \n",
    "                        'NearDogsWeek', 'NearCatsWeek'):\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # fix the inconsistant data\n",
    "    data = sleepPrior(category, data)\n",
    "    data = prescription(category, data)\n",
    "    data = eyes(category, data)\n",
    "    data = perWeek(category, data)\n",
    "    data = numToWords(category, data)\n",
    "    data = mouthwash(category, data)\n",
    "    data = religious(category, data)\n",
    "    data = orientation(category, data)\n",
    "\n",
    "    #change the category into its own separate dataframe\n",
    "\n",
    "    #get list of subcategories\n",
    "    try:\n",
    "        data[category.name] = data[category.name].str.lower()\n",
    "    except:\n",
    "        data[category.name]\n",
    "    subcategory = data[category.name].drop_duplicates().values.tolist()\n",
    "    \n",
    "    #remove nans (where people didn't put in an answer)\n",
    "    try:\n",
    "        subcategory = [subcat.lower().strip() for subcat in subcategory if str(subcat) != 'nan' \n",
    "                   and str(subcat) != 'don\\'t know' and str(subcat) != 'do not know' and str(subcat) != 'don?t know']\n",
    "    except:\n",
    "        subcategory = [subcat for subcat in subcategory if str(subcat) != 'nan' \n",
    "                   and str(subcat) != 'don\\'t know' and str(subcat) != 'do not know' and str(subcat) != 'don?t know']\n",
    "        \n",
    "    #remove any more duplicates\n",
    "    subcategory = list(set(subcategory))\n",
    "\n",
    "    #remove outliers/format the data for specific categories\n",
    "    if category == Col.Spicy:\n",
    "        subcategory.remove('sometimes')\n",
    "    if category == Col.Hands:\n",
    "        subcategory.remove('ambidextrous')\n",
    "    if category == Col.BrushTeethWeek:\n",
    "        subcategory.remove('42689');\n",
    "    \n",
    "\n",
    "    #decide on which test to use\n",
    "    if len(subcategory) == 2:\n",
    "        test = Test.Ttest\n",
    "    else:\n",
    "        test = Test.Anova\n",
    "        \n",
    "    #load dataframes for each subcategory of all bacterial classes\\n\",\n",
    "    for x in range(0, len(subcategory)):\n",
    "        categoryDF.append(data[data[category.name] == subcategory[x]].iloc[:, 83:125])\n",
    "        \n",
    "    print(category.name)\n",
    "    print(subcategory)\n",
    "        \n",
    "    #go through all bacterial classes to perform tests on them\n",
    "    sigClassCount = 0\n",
    "    total += 1\n",
    "    markCat = False\n",
    "    for x in range(0, 42):\n",
    "        \n",
    "        #perform t-test if applicable\n",
    "        if test == Test.Ttest:\n",
    "            ttest = ttest_ind(categoryDF[0].iloc[:, x],categoryDF[1].iloc[:, x])\n",
    "            pvalue = ttest[1]\n",
    "            \n",
    "        #perform anova test is applicable\n",
    "        if test == Test.Anova:\n",
    "            #keep track of how many subcategories there are to put into anova test\n",
    "            arg = []\n",
    "            for y in range(0, len(subcategory)):\n",
    "                arg.append(categoryDF[y].iloc[:, x])\n",
    "            anova = stats.f_oneway(*(a for a in arg))\n",
    "            pvalue = anova[1]\n",
    "\n",
    "        #keep a list of all bacteria classes and their index\n",
    "        if len(bactClasses) != 42:\n",
    "            bactClasses.append(categoryDF[0].iloc[:,x].name)\n",
    "\n",
    "        #print classes that are significant\n",
    "        if pvalue <= 0.05 or showAllClasses:\n",
    "            markCat = True\n",
    "            #keep track of significant classes\n",
    "            sigClassCount += 1\n",
    "            className = categoryDF[0].iloc[:,x].name\n",
    "            if className not in bactClassDict:\n",
    "                bactClassDict[className] = 1\n",
    "            else:\n",
    "                bactClassDict[className] += 1\n",
    "            sigClasses.append(className)\n",
    "\n",
    "            print(categoryDF[0].iloc[:,x].name, \"\\nP-value: {:4.6f}\".format(pvalue))\n",
    "    \n",
    "    if markCat:\n",
    "        sumCat += 1\n",
    "\n",
    "    # print out info for categories with high numbers of significant classes  \n",
    "#     if sigClassCount >= 4: \n",
    "#         catData = []\n",
    "#         print(sigClassCount)\n",
    "#         print(sigClasses)\n",
    "#         for subcat in data[category.name]:\n",
    "#             if subcat in subcategory:\n",
    "#                 catData.append(subcat)\n",
    "#         print(len(catData))\n",
    "#         print(catData)\n",
    "    \n",
    "    print('\\n')\n",
    "        \n",
    "    #get and set inputs, key = bactClass, value = list of all values under that class - Design 1\n",
    "#     for c in sigClasses:\n",
    "#         classValue = []\n",
    "#         for index, row in data.iterrows():\n",
    "#             if row[category.name] in subcategory:\n",
    "#                 classValue.append(row[c])\n",
    "#         inputs[c] = classValue\n",
    "#     print(inputs)\n",
    "\n",
    "\n",
    "    # UNCOMMENT BELOW HERE FOR NN TESTING\n",
    "\n",
    "    #get and set inputs Design 2\n",
    "    for index, row in data.iterrows():\n",
    "        classValue = []\n",
    "        for c in sigClasses:\n",
    "            if row[category.name] in subcategory:\n",
    "                classValue.append(row[c])\n",
    "        if row[category.name] in subcategory:\n",
    "            inputs.append(classValue)\n",
    "    print(len(inputs), inputs)\n",
    "    \n",
    "    #add subcategories to outputMap\n",
    "    outputMap[category.name] = subcategory\n",
    "#     print(outputMap)\n",
    "    \n",
    "    #get and set outputs so that it looks like [a,b,c]\n",
    "    outputs = []\n",
    "    for index, row in data.iterrows():\n",
    "        if row[category.name] in subcategory:\n",
    "            outputs.append(row[category.name])\n",
    "#     print(len(outputs), outputs)\n",
    "    \n",
    "    #replace string outputs with numbers\n",
    "    if outputs and isinstance(outputs[0], str):\n",
    "        for i in range(0, len(outputs)):\n",
    "            outputs[i] = subcategory.index(outputs[i])\n",
    "#     print(len(outputs), outputs)\n",
    "    \n",
    "    #separate training and testing data\n",
    "    for i in range(0, len(inputs)):\n",
    "        if i % 2 == 1:\n",
    "            train_inputs.append(inputs[i])\n",
    "            train_outputs.append(outputs[i])\n",
    "        else:\n",
    "            test_inputs.append(inputs[i])\n",
    "            test_outputs.append(outputs[i])  \n",
    "    \n",
    "    \n",
    "\n",
    "class Main():\n",
    "    data = pd.read_csv('MasterSheet.csv')\n",
    "    outputMap = {}\n",
    "    showAllClasses = False\n",
    "    \n",
    "    runTests(data, Col.Gender, outputMap, showAllClasses)\n",
    "    \n",
    "#     for x in range(1, 82):\n",
    "#         runTests(data, Col(x), outputMap, showAllClasses)\n",
    "        \n",
    "    #print out the highest appearing sig class - information tim requested\n",
    "#     sort = sorted(bactClassDict.items(), key=lambda x: x[1], reverse=True)\n",
    "#     print(sort)\n",
    "    \n",
    "    print(\"sig categories \", repr(sumCat), \"/\", repr(total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 53 samples, validate on 53 samples\n",
      "Epoch 1/500\n",
      "53/53 [==============================] - 5s 92ms/step - loss: 2.6173 - acc: 0.1321 - val_loss: 1.3188 - val_acc: 0.3585\n",
      "Epoch 2/500\n",
      "53/53 [==============================] - 0s 320us/step - loss: 1.4865 - acc: 0.4528 - val_loss: 1.0011 - val_acc: 0.5094\n",
      "Epoch 3/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 1.1818 - acc: 0.4340 - val_loss: 0.9077 - val_acc: 0.5472\n",
      "Epoch 4/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 1.1858 - acc: 0.5094 - val_loss: 0.8344 - val_acc: 0.5849\n",
      "Epoch 5/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 1.1181 - acc: 0.4151 - val_loss: 0.7545 - val_acc: 0.5849\n",
      "Epoch 6/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 1.0436 - acc: 0.4906 - val_loss: 0.7101 - val_acc: 0.6226\n",
      "Epoch 7/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7787 - acc: 0.6226 - val_loss: 0.6774 - val_acc: 0.6604\n",
      "Epoch 8/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.8771 - acc: 0.5849 - val_loss: 0.6586 - val_acc: 0.6792\n",
      "Epoch 9/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.8704 - acc: 0.5660 - val_loss: 0.6479 - val_acc: 0.6792\n",
      "Epoch 10/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.8718 - acc: 0.5472 - val_loss: 0.6472 - val_acc: 0.6604\n",
      "Epoch 11/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.7619 - acc: 0.6981 - val_loss: 0.6535 - val_acc: 0.6415\n",
      "Epoch 12/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.7488 - acc: 0.6792 - val_loss: 0.6505 - val_acc: 0.6415\n",
      "Epoch 13/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.7991 - acc: 0.6604 - val_loss: 0.6363 - val_acc: 0.6792\n",
      "Epoch 14/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6747 - acc: 0.6604 - val_loss: 0.6316 - val_acc: 0.7170\n",
      "Epoch 15/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.7370 - acc: 0.6226 - val_loss: 0.6266 - val_acc: 0.6981\n",
      "Epoch 16/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6163 - acc: 0.7547 - val_loss: 0.6168 - val_acc: 0.6792\n",
      "Epoch 17/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.7610 - acc: 0.5849 - val_loss: 0.6111 - val_acc: 0.6792\n",
      "Epoch 18/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.7560 - acc: 0.5849 - val_loss: 0.6099 - val_acc: 0.6604\n",
      "Epoch 19/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.7086 - acc: 0.6792 - val_loss: 0.6099 - val_acc: 0.6792\n",
      "Epoch 20/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5896 - acc: 0.7170 - val_loss: 0.6091 - val_acc: 0.6792\n",
      "Epoch 21/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.7770 - acc: 0.5849 - val_loss: 0.6090 - val_acc: 0.6981\n",
      "Epoch 22/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6802 - acc: 0.6038 - val_loss: 0.6130 - val_acc: 0.6792\n",
      "Epoch 23/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.7185 - acc: 0.6415 - val_loss: 0.6223 - val_acc: 0.6792\n",
      "Epoch 24/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6869 - acc: 0.6981 - val_loss: 0.6335 - val_acc: 0.6604\n",
      "Epoch 25/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5723 - acc: 0.7170 - val_loss: 0.6361 - val_acc: 0.6604\n",
      "Epoch 26/500\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.5974 - acc: 0.7358 - val_loss: 0.6275 - val_acc: 0.6604\n",
      "Epoch 27/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6520 - acc: 0.6604 - val_loss: 0.6196 - val_acc: 0.6604\n",
      "Epoch 28/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6560 - acc: 0.6981 - val_loss: 0.6075 - val_acc: 0.6604\n",
      "Epoch 29/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6192 - acc: 0.6792 - val_loss: 0.6028 - val_acc: 0.6981\n",
      "Epoch 30/500\n",
      "53/53 [==============================] - 0s 301us/step - loss: 0.6535 - acc: 0.6604 - val_loss: 0.6030 - val_acc: 0.6981\n",
      "Epoch 31/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5683 - acc: 0.7358 - val_loss: 0.6100 - val_acc: 0.6792\n",
      "Epoch 32/500\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.6638 - acc: 0.6981 - val_loss: 0.6089 - val_acc: 0.6981\n",
      "Epoch 33/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6921 - acc: 0.6226 - val_loss: 0.5985 - val_acc: 0.6981\n",
      "Epoch 34/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5884 - acc: 0.6604 - val_loss: 0.6064 - val_acc: 0.6604\n",
      "Epoch 35/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6728 - acc: 0.6604 - val_loss: 0.6163 - val_acc: 0.6604\n",
      "Epoch 36/500\n",
      "53/53 [==============================] - 0s 320us/step - loss: 0.7951 - acc: 0.5849 - val_loss: 0.6343 - val_acc: 0.6792\n",
      "Epoch 37/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6532 - acc: 0.6226 - val_loss: 0.6282 - val_acc: 0.6604\n",
      "Epoch 38/500\n",
      "53/53 [==============================] - 0s 339us/step - loss: 0.5516 - acc: 0.7170 - val_loss: 0.6114 - val_acc: 0.6604\n",
      "Epoch 39/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6138 - acc: 0.6981 - val_loss: 0.5999 - val_acc: 0.6604\n",
      "Epoch 40/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5804 - acc: 0.7358 - val_loss: 0.5967 - val_acc: 0.6981\n",
      "Epoch 41/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7009 - acc: 0.6226 - val_loss: 0.6063 - val_acc: 0.6792\n",
      "Epoch 42/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.7110 - acc: 0.6604 - val_loss: 0.6113 - val_acc: 0.6792\n",
      "Epoch 43/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6982 - acc: 0.6792 - val_loss: 0.6066 - val_acc: 0.6792\n",
      "Epoch 44/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5514 - acc: 0.6604 - val_loss: 0.5960 - val_acc: 0.6792\n",
      "Epoch 45/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.7331 - acc: 0.6415 - val_loss: 0.6065 - val_acc: 0.6604\n",
      "Epoch 46/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6284 - acc: 0.6604 - val_loss: 0.6268 - val_acc: 0.6604\n",
      "Epoch 47/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7054 - acc: 0.6604 - val_loss: 0.6449 - val_acc: 0.6792\n",
      "Epoch 48/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6893 - acc: 0.6604 - val_loss: 0.6444 - val_acc: 0.6792\n",
      "Epoch 49/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6644 - acc: 0.6415 - val_loss: 0.6285 - val_acc: 0.6604\n",
      "Epoch 50/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.7286 - acc: 0.6226 - val_loss: 0.6081 - val_acc: 0.6415\n",
      "Epoch 51/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6926 - acc: 0.6981 - val_loss: 0.6000 - val_acc: 0.6792\n",
      "Epoch 52/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.7271 - acc: 0.6415 - val_loss: 0.5995 - val_acc: 0.6981\n",
      "Epoch 53/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6754 - acc: 0.5849 - val_loss: 0.6017 - val_acc: 0.6981\n",
      "Epoch 54/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7369 - acc: 0.6415 - val_loss: 0.6008 - val_acc: 0.6981\n",
      "Epoch 55/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5830 - acc: 0.7358 - val_loss: 0.5999 - val_acc: 0.6981\n",
      "Epoch 56/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6023 - acc: 0.6226 - val_loss: 0.5999 - val_acc: 0.6981\n",
      "Epoch 57/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.6043 - acc: 0.6792 - val_loss: 0.6003 - val_acc: 0.6792\n",
      "Epoch 58/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7302 - acc: 0.6415 - val_loss: 0.6019 - val_acc: 0.6792\n",
      "Epoch 59/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6809 - acc: 0.6415 - val_loss: 0.6024 - val_acc: 0.6792\n",
      "Epoch 60/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5635 - acc: 0.6981 - val_loss: 0.6015 - val_acc: 0.6792\n",
      "Epoch 61/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6519 - acc: 0.6792 - val_loss: 0.6006 - val_acc: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.7282 - acc: 0.6226 - val_loss: 0.5993 - val_acc: 0.6981\n",
      "Epoch 63/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.7422 - acc: 0.5849 - val_loss: 0.6004 - val_acc: 0.6981\n",
      "Epoch 64/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.6659 - acc: 0.6415 - val_loss: 0.6001 - val_acc: 0.6981\n",
      "Epoch 65/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5867 - acc: 0.656 - 0s 414us/step - loss: 0.6711 - acc: 0.6038 - val_loss: 0.5995 - val_acc: 0.6981\n",
      "Epoch 66/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5758 - acc: 0.7170 - val_loss: 0.5992 - val_acc: 0.6981\n",
      "Epoch 67/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6370 - acc: 0.6792 - val_loss: 0.6003 - val_acc: 0.6792\n",
      "Epoch 68/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5968 - acc: 0.7170 - val_loss: 0.6023 - val_acc: 0.6604\n",
      "Epoch 69/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6853 - acc: 0.6604 - val_loss: 0.6018 - val_acc: 0.6604\n",
      "Epoch 70/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5987 - acc: 0.6981 - val_loss: 0.6024 - val_acc: 0.6604\n",
      "Epoch 71/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6012 - acc: 0.7170 - val_loss: 0.6011 - val_acc: 0.6604\n",
      "Epoch 72/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6288 - acc: 0.6226 - val_loss: 0.5983 - val_acc: 0.6981\n",
      "Epoch 73/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6150 - acc: 0.6604 - val_loss: 0.5973 - val_acc: 0.6981\n",
      "Epoch 74/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6724 - acc: 0.6415 - val_loss: 0.5968 - val_acc: 0.6981\n",
      "Epoch 75/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.7055 - acc: 0.6415 - val_loss: 0.5965 - val_acc: 0.6981\n",
      "Epoch 76/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6867 - acc: 0.6038 - val_loss: 0.5960 - val_acc: 0.6981\n",
      "Epoch 77/500\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.6596 - acc: 0.6604 - val_loss: 0.5957 - val_acc: 0.6981\n",
      "Epoch 78/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6083 - acc: 0.6792 - val_loss: 0.5962 - val_acc: 0.6792\n",
      "Epoch 79/500\n",
      "53/53 [==============================] - 0s 734us/step - loss: 0.6541 - acc: 0.6415 - val_loss: 0.5997 - val_acc: 0.6604\n",
      "Epoch 80/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5556 - acc: 0.7170 - val_loss: 0.6015 - val_acc: 0.6604\n",
      "Epoch 81/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6889 - acc: 0.6792 - val_loss: 0.6010 - val_acc: 0.6604\n",
      "Epoch 82/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6343 - acc: 0.6604 - val_loss: 0.5979 - val_acc: 0.6604\n",
      "Epoch 83/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5945 - acc: 0.7170 - val_loss: 0.5958 - val_acc: 0.6981\n",
      "Epoch 84/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6736 - acc: 0.7170 - val_loss: 0.5965 - val_acc: 0.6981\n",
      "Epoch 85/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6466 - acc: 0.6415 - val_loss: 0.5964 - val_acc: 0.6981\n",
      "Epoch 86/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5805 - acc: 0.6792 - val_loss: 0.5958 - val_acc: 0.6981\n",
      "Epoch 87/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.7201 - acc: 0.6604 - val_loss: 0.5968 - val_acc: 0.6792\n",
      "Epoch 88/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6158 - acc: 0.6981 - val_loss: 0.5996 - val_acc: 0.6604\n",
      "Epoch 89/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6551 - acc: 0.6038 - val_loss: 0.6070 - val_acc: 0.6604\n",
      "Epoch 90/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6714 - acc: 0.6981 - val_loss: 0.6154 - val_acc: 0.6604\n",
      "Epoch 91/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6331 - acc: 0.6604 - val_loss: 0.6185 - val_acc: 0.6604\n",
      "Epoch 92/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6674 - acc: 0.6038 - val_loss: 0.6185 - val_acc: 0.6604\n",
      "Epoch 93/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6922 - acc: 0.6226 - val_loss: 0.6157 - val_acc: 0.6604\n",
      "Epoch 94/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6576 - acc: 0.7358 - val_loss: 0.6082 - val_acc: 0.6604\n",
      "Epoch 95/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5221 - acc: 0.7547 - val_loss: 0.6005 - val_acc: 0.6604\n",
      "Epoch 96/500\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.6312 - acc: 0.6038 - val_loss: 0.5972 - val_acc: 0.6792\n",
      "Epoch 97/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5678 - acc: 0.7170 - val_loss: 0.5968 - val_acc: 0.6981\n",
      "Epoch 98/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5683 - acc: 0.6604 - val_loss: 0.5981 - val_acc: 0.6981\n",
      "Epoch 99/500\n",
      "53/53 [==============================] - 0s 847us/step - loss: 0.6169 - acc: 0.6604 - val_loss: 0.5991 - val_acc: 0.6981\n",
      "Epoch 100/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6635 - acc: 0.5849 - val_loss: 0.5991 - val_acc: 0.6981\n",
      "Epoch 101/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5992 - acc: 0.6604 - val_loss: 0.5970 - val_acc: 0.6981\n",
      "Epoch 102/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6894 - acc: 0.6604 - val_loss: 0.5978 - val_acc: 0.6792\n",
      "Epoch 103/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6594 - acc: 0.6604 - val_loss: 0.5994 - val_acc: 0.6604\n",
      "Epoch 104/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6302 - acc: 0.6226 - val_loss: 0.6034 - val_acc: 0.6604\n",
      "Epoch 105/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6502 - acc: 0.6792 - val_loss: 0.6047 - val_acc: 0.6604\n",
      "Epoch 106/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6014 - acc: 0.6981 - val_loss: 0.6011 - val_acc: 0.6604\n",
      "Epoch 107/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6221 - acc: 0.6981 - val_loss: 0.5986 - val_acc: 0.6604\n",
      "Epoch 108/500\n",
      "53/53 [==============================] - 0s 753us/step - loss: 0.5780 - acc: 0.7358 - val_loss: 0.5964 - val_acc: 0.6792\n",
      "Epoch 109/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5733 - acc: 0.6792 - val_loss: 0.5963 - val_acc: 0.6792\n",
      "Epoch 110/500\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.5315 - acc: 0.7170 - val_loss: 0.5972 - val_acc: 0.6604\n",
      "Epoch 111/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6099 - acc: 0.6604 - val_loss: 0.6001 - val_acc: 0.6604\n",
      "Epoch 112/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6197 - acc: 0.6981 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 113/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5941 - acc: 0.6792 - val_loss: 0.6010 - val_acc: 0.6604\n",
      "Epoch 114/500\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5994 - acc: 0.6038 - val_loss: 0.5980 - val_acc: 0.6604\n",
      "Epoch 115/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6066 - acc: 0.6415 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 116/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.6432 - acc: 0.7170 - val_loss: 0.5964 - val_acc: 0.6792\n",
      "Epoch 117/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5445 - acc: 0.7170 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 118/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6108 - acc: 0.6981 - val_loss: 0.5979 - val_acc: 0.6604\n",
      "Epoch 119/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6078 - acc: 0.6792 - val_loss: 0.6003 - val_acc: 0.6604\n",
      "Epoch 120/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6597 - acc: 0.6792 - val_loss: 0.5988 - val_acc: 0.6604\n",
      "Epoch 121/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6374 - acc: 0.7170 - val_loss: 0.5994 - val_acc: 0.6604\n",
      "Epoch 122/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5683 - acc: 0.687 - 0s 565us/step - loss: 0.5635 - acc: 0.6981 - val_loss: 0.5995 - val_acc: 0.6604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6331 - acc: 0.6415 - val_loss: 0.6014 - val_acc: 0.6604\n",
      "Epoch 124/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6049 - acc: 0.7170 - val_loss: 0.6007 - val_acc: 0.6604\n",
      "Epoch 125/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5756 - acc: 0.6792 - val_loss: 0.5993 - val_acc: 0.6604\n",
      "Epoch 126/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6792 - acc: 0.6226 - val_loss: 0.5987 - val_acc: 0.6604\n",
      "Epoch 127/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5453 - acc: 0.7736 - val_loss: 0.5973 - val_acc: 0.6981\n",
      "Epoch 128/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6361 - acc: 0.7170 - val_loss: 0.5980 - val_acc: 0.6981\n",
      "Epoch 129/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6078 - acc: 0.6981 - val_loss: 0.5994 - val_acc: 0.6604\n",
      "Epoch 130/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6542 - acc: 0.6792 - val_loss: 0.6001 - val_acc: 0.6604\n",
      "Epoch 131/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6296 - acc: 0.6604 - val_loss: 0.5995 - val_acc: 0.6792\n",
      "Epoch 132/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5542 - acc: 0.6792 - val_loss: 0.6008 - val_acc: 0.6604\n",
      "Epoch 133/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5331 - acc: 0.7547 - val_loss: 0.6022 - val_acc: 0.6604\n",
      "Epoch 134/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6629 - acc: 0.6604 - val_loss: 0.6027 - val_acc: 0.6604\n",
      "Epoch 135/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5691 - acc: 0.7547 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 136/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5530 - acc: 0.6604 - val_loss: 0.5994 - val_acc: 0.6792\n",
      "Epoch 137/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6810 - acc: 0.6038 - val_loss: 0.5974 - val_acc: 0.6981\n",
      "Epoch 138/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5756 - acc: 0.6792 - val_loss: 0.5971 - val_acc: 0.6981\n",
      "Epoch 139/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6511 - acc: 0.6038 - val_loss: 0.5969 - val_acc: 0.6981\n",
      "Epoch 140/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6077 - acc: 0.6792 - val_loss: 0.5962 - val_acc: 0.6792\n",
      "Epoch 141/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5066 - acc: 0.7358 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 142/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.7291 - acc: 0.6415 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 143/500\n",
      "53/53 [==============================] - 0s 809us/step - loss: 0.6001 - acc: 0.6792 - val_loss: 0.5987 - val_acc: 0.6604\n",
      "Epoch 144/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6211 - acc: 0.6981 - val_loss: 0.6012 - val_acc: 0.6604\n",
      "Epoch 145/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5943 - acc: 0.6415 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 146/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5866 - acc: 0.6981 - val_loss: 0.5998 - val_acc: 0.6604\n",
      "Epoch 147/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5662 - acc: 0.6792 - val_loss: 0.5993 - val_acc: 0.6604\n",
      "Epoch 148/500\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.5858 - acc: 0.6981 - val_loss: 0.5976 - val_acc: 0.6604\n",
      "Epoch 149/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6871 - acc: 0.6415 - val_loss: 0.5958 - val_acc: 0.6792\n",
      "Epoch 150/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6132 - acc: 0.6981 - val_loss: 0.5958 - val_acc: 0.6792\n",
      "Epoch 151/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5884 - acc: 0.7358 - val_loss: 0.5957 - val_acc: 0.6792\n",
      "Epoch 152/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5822 - acc: 0.7170 - val_loss: 0.5956 - val_acc: 0.6792\n",
      "Epoch 153/500\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.6195 - acc: 0.6226 - val_loss: 0.5967 - val_acc: 0.6604\n",
      "Epoch 154/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5946 - acc: 0.6604 - val_loss: 0.5967 - val_acc: 0.6604\n",
      "Epoch 155/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6414 - acc: 0.6415 - val_loss: 0.5994 - val_acc: 0.6604\n",
      "Epoch 156/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5590 - acc: 0.6604 - val_loss: 0.6020 - val_acc: 0.6604\n",
      "Epoch 157/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5810 - acc: 0.6792 - val_loss: 0.5980 - val_acc: 0.6604\n",
      "Epoch 158/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5632 - acc: 0.7170 - val_loss: 0.5961 - val_acc: 0.6792\n",
      "Epoch 159/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5497 - acc: 0.6792 - val_loss: 0.5956 - val_acc: 0.6792\n",
      "Epoch 160/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5724 - acc: 0.6792 - val_loss: 0.5954 - val_acc: 0.6792\n",
      "Epoch 161/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.5727 - acc: 0.6415 - val_loss: 0.5957 - val_acc: 0.6792\n",
      "Epoch 162/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6477 - acc: 0.6792 - val_loss: 0.5958 - val_acc: 0.6981\n",
      "Epoch 163/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6327 - acc: 0.6604 - val_loss: 0.5959 - val_acc: 0.6981\n",
      "Epoch 164/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5756 - acc: 0.6792 - val_loss: 0.5963 - val_acc: 0.6981\n",
      "Epoch 165/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6236 - acc: 0.6604 - val_loss: 0.5965 - val_acc: 0.6981\n",
      "Epoch 166/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5638 - acc: 0.6981 - val_loss: 0.5958 - val_acc: 0.6981\n",
      "Epoch 167/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5974 - acc: 0.6604 - val_loss: 0.5956 - val_acc: 0.6792\n",
      "Epoch 168/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6089 - acc: 0.6792 - val_loss: 0.5983 - val_acc: 0.6604\n",
      "Epoch 169/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5978 - acc: 0.6604 - val_loss: 0.6028 - val_acc: 0.6604\n",
      "Epoch 170/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5363 - acc: 0.6792 - val_loss: 0.6033 - val_acc: 0.6604\n",
      "Epoch 171/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.6152 - acc: 0.6604 - val_loss: 0.6041 - val_acc: 0.6604\n",
      "Epoch 172/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5882 - acc: 0.6604 - val_loss: 0.6034 - val_acc: 0.6604\n",
      "Epoch 173/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6037 - acc: 0.7170 - val_loss: 0.6038 - val_acc: 0.6604\n",
      "Epoch 174/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5757 - acc: 0.7170 - val_loss: 0.6055 - val_acc: 0.6604\n",
      "Epoch 175/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5011 - acc: 0.7547 - val_loss: 0.6049 - val_acc: 0.6604\n",
      "Epoch 176/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5929 - acc: 0.7170 - val_loss: 0.6025 - val_acc: 0.6604\n",
      "Epoch 177/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5916 - acc: 0.6981 - val_loss: 0.6002 - val_acc: 0.6604\n",
      "Epoch 178/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5292 - acc: 0.7736 - val_loss: 0.5989 - val_acc: 0.6792\n",
      "Epoch 179/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5684 - acc: 0.6604 - val_loss: 0.5996 - val_acc: 0.6604\n",
      "Epoch 180/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5696 - acc: 0.6604 - val_loss: 0.5991 - val_acc: 0.6792\n",
      "Epoch 181/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5732 - acc: 0.7170 - val_loss: 0.6016 - val_acc: 0.6604\n",
      "Epoch 182/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5697 - acc: 0.6415 - val_loss: 0.6035 - val_acc: 0.6604\n",
      "Epoch 183/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.4895 - acc: 0.6981 - val_loss: 0.6027 - val_acc: 0.6604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5393 - acc: 0.7547 - val_loss: 0.6002 - val_acc: 0.6604\n",
      "Epoch 185/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5822 - acc: 0.6792 - val_loss: 0.5976 - val_acc: 0.6792\n",
      "Epoch 186/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6197 - acc: 0.5849 - val_loss: 0.5974 - val_acc: 0.6981\n",
      "Epoch 187/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5854 - acc: 0.6981 - val_loss: 0.5972 - val_acc: 0.6981\n",
      "Epoch 188/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5372 - acc: 0.7170 - val_loss: 0.5974 - val_acc: 0.6792\n",
      "Epoch 189/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6246 - acc: 0.6415 - val_loss: 0.5976 - val_acc: 0.6792\n",
      "Epoch 190/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5828 - acc: 0.6792 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 191/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5257 - acc: 0.8113 - val_loss: 0.5963 - val_acc: 0.6792\n",
      "Epoch 192/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6303 - acc: 0.6226 - val_loss: 0.5961 - val_acc: 0.6981\n",
      "Epoch 193/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5530 - acc: 0.6792 - val_loss: 0.5962 - val_acc: 0.6981\n",
      "Epoch 194/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6001 - acc: 0.6981 - val_loss: 0.5966 - val_acc: 0.6981\n",
      "Epoch 195/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5209 - acc: 0.7925 - val_loss: 0.5963 - val_acc: 0.6981\n",
      "Epoch 196/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6404 - acc: 0.6604 - val_loss: 0.5958 - val_acc: 0.6981\n",
      "Epoch 197/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6531 - acc: 0.6038 - val_loss: 0.5962 - val_acc: 0.6792\n",
      "Epoch 198/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5919 - acc: 0.6792 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 199/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6513 - acc: 0.7170 - val_loss: 0.6005 - val_acc: 0.6604\n",
      "Epoch 200/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5378 - acc: 0.6981 - val_loss: 0.6027 - val_acc: 0.6604\n",
      "Epoch 201/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5592 - acc: 0.7170 - val_loss: 0.6004 - val_acc: 0.6604\n",
      "Epoch 202/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6111 - acc: 0.7358 - val_loss: 0.5958 - val_acc: 0.6792\n",
      "Epoch 203/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6339 - acc: 0.5472 - val_loss: 0.5964 - val_acc: 0.6981\n",
      "Epoch 204/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5832 - acc: 0.6981 - val_loss: 0.5967 - val_acc: 0.6981\n",
      "Epoch 205/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5776 - acc: 0.6792 - val_loss: 0.5956 - val_acc: 0.6981\n",
      "Epoch 206/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5868 - acc: 0.6604 - val_loss: 0.5955 - val_acc: 0.6792\n",
      "Epoch 207/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5855 - acc: 0.6604 - val_loss: 0.5977 - val_acc: 0.6604\n",
      "Epoch 208/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5413 - acc: 0.7547 - val_loss: 0.5995 - val_acc: 0.6604\n",
      "Epoch 209/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5742 - acc: 0.6604 - val_loss: 0.6010 - val_acc: 0.6604\n",
      "Epoch 210/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5470 - acc: 0.6792 - val_loss: 0.6009 - val_acc: 0.6604\n",
      "Epoch 211/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5853 - acc: 0.7170 - val_loss: 0.6006 - val_acc: 0.6604\n",
      "Epoch 212/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6277 - acc: 0.6604 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 213/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6002 - acc: 0.6415 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 214/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6471 - acc: 0.6226 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 215/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6331 - acc: 0.7358 - val_loss: 0.5960 - val_acc: 0.6792\n",
      "Epoch 216/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5438 - acc: 0.7736 - val_loss: 0.5964 - val_acc: 0.6792\n",
      "Epoch 217/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5801 - acc: 0.6981 - val_loss: 0.5968 - val_acc: 0.6792\n",
      "Epoch 218/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5810 - acc: 0.6792 - val_loss: 0.5980 - val_acc: 0.6604\n",
      "Epoch 219/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6141 - acc: 0.6415 - val_loss: 0.6020 - val_acc: 0.6604\n",
      "Epoch 220/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5132 - acc: 0.7358 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 221/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5198 - acc: 0.7547 - val_loss: 0.5984 - val_acc: 0.6792\n",
      "Epoch 222/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5632 - acc: 0.7547 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 223/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5481 - acc: 0.6792 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 224/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6315 - acc: 0.6226 - val_loss: 0.5982 - val_acc: 0.6792\n",
      "Epoch 225/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5661 - acc: 0.6792 - val_loss: 0.6017 - val_acc: 0.6604\n",
      "Epoch 226/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5999 - acc: 0.6226 - val_loss: 0.6036 - val_acc: 0.6604\n",
      "Epoch 227/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5433 - acc: 0.7170 - val_loss: 0.6025 - val_acc: 0.6604\n",
      "Epoch 228/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6073 - acc: 0.6604 - val_loss: 0.6011 - val_acc: 0.6604\n",
      "Epoch 229/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5419 - acc: 0.7170 - val_loss: 0.6000 - val_acc: 0.6792\n",
      "Epoch 230/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5671 - acc: 0.6981 - val_loss: 0.5984 - val_acc: 0.6792\n",
      "Epoch 231/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5767 - acc: 0.6792 - val_loss: 0.5974 - val_acc: 0.6792\n",
      "Epoch 232/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5710 - acc: 0.6792 - val_loss: 0.5972 - val_acc: 0.6792\n",
      "Epoch 233/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5275 - acc: 0.6604 - val_loss: 0.5968 - val_acc: 0.6792\n",
      "Epoch 234/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5180 - acc: 0.6981 - val_loss: 0.5975 - val_acc: 0.6792\n",
      "Epoch 235/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6194 - acc: 0.6792 - val_loss: 0.6016 - val_acc: 0.6604\n",
      "Epoch 236/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6030 - acc: 0.6792 - val_loss: 0.6100 - val_acc: 0.6604\n",
      "Epoch 237/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5710 - acc: 0.7358 - val_loss: 0.6143 - val_acc: 0.6604\n",
      "Epoch 238/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5590 - acc: 0.6792 - val_loss: 0.6099 - val_acc: 0.6604\n",
      "Epoch 239/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6150 - acc: 0.6792 - val_loss: 0.6065 - val_acc: 0.6604\n",
      "Epoch 240/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5248 - acc: 0.6981 - val_loss: 0.6031 - val_acc: 0.6604\n",
      "Epoch 241/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5411 - acc: 0.7547 - val_loss: 0.5992 - val_acc: 0.6792\n",
      "Epoch 242/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5952 - acc: 0.6792 - val_loss: 0.5976 - val_acc: 0.6792\n",
      "Epoch 243/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.7028 - acc: 0.5849 - val_loss: 0.5974 - val_acc: 0.6981\n",
      "Epoch 244/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5844 - acc: 0.6792 - val_loss: 0.5975 - val_acc: 0.6981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6049 - acc: 0.6415 - val_loss: 0.5974 - val_acc: 0.6981\n",
      "Epoch 246/500\n",
      "53/53 [==============================] - 0s 357us/step - loss: 0.5363 - acc: 0.6981 - val_loss: 0.5996 - val_acc: 0.6792\n",
      "Epoch 247/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6064 - acc: 0.6981 - val_loss: 0.6030 - val_acc: 0.6604\n",
      "Epoch 248/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.6062 - acc: 0.6981 - val_loss: 0.6018 - val_acc: 0.6604\n",
      "Epoch 249/500\n",
      "53/53 [==============================] - 0s 715us/step - loss: 0.5615 - acc: 0.6792 - val_loss: 0.6016 - val_acc: 0.6792\n",
      "Epoch 250/500\n",
      "53/53 [==============================] - 0s 790us/step - loss: 0.5872 - acc: 0.6792 - val_loss: 0.6012 - val_acc: 0.6792\n",
      "Epoch 251/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.6054 - acc: 0.6981 - val_loss: 0.6008 - val_acc: 0.6792\n",
      "Epoch 252/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6110 - acc: 0.6415 - val_loss: 0.5983 - val_acc: 0.6792\n",
      "Epoch 253/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6126 - acc: 0.6415 - val_loss: 0.5984 - val_acc: 0.6792\n",
      "Epoch 254/500\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.5972 - acc: 0.6415 - val_loss: 0.5983 - val_acc: 0.6792\n",
      "Epoch 255/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6270 - acc: 0.6792 - val_loss: 0.5989 - val_acc: 0.6792\n",
      "Epoch 256/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5520 - acc: 0.7358 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 257/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5705 - acc: 0.6792 - val_loss: 0.6018 - val_acc: 0.6604\n",
      "Epoch 258/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5604 - acc: 0.7170 - val_loss: 0.6021 - val_acc: 0.6604\n",
      "Epoch 259/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.6335 - acc: 0.6604 - val_loss: 0.6020 - val_acc: 0.6604\n",
      "Epoch 260/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5538 - acc: 0.7358 - val_loss: 0.6036 - val_acc: 0.6604\n",
      "Epoch 261/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.6050 - acc: 0.6415 - val_loss: 0.6014 - val_acc: 0.6604\n",
      "Epoch 262/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5735 - acc: 0.6792 - val_loss: 0.5986 - val_acc: 0.6604\n",
      "Epoch 263/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5739 - acc: 0.6981 - val_loss: 0.5961 - val_acc: 0.6792\n",
      "Epoch 264/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5695 - acc: 0.6792 - val_loss: 0.5956 - val_acc: 0.6792\n",
      "Epoch 265/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.6015 - acc: 0.6604 - val_loss: 0.5953 - val_acc: 0.6792\n",
      "Epoch 266/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5181 - acc: 0.6792 - val_loss: 0.5951 - val_acc: 0.6792\n",
      "Epoch 267/500\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5663 - acc: 0.7170 - val_loss: 0.5950 - val_acc: 0.6792\n",
      "Epoch 268/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5476 - acc: 0.7547 - val_loss: 0.5968 - val_acc: 0.6792\n",
      "Epoch 269/500\n",
      "53/53 [==============================] - 0s 640us/step - loss: 0.5746 - acc: 0.7170 - val_loss: 0.6020 - val_acc: 0.6604\n",
      "Epoch 270/500\n",
      "53/53 [==============================] - 0s 696us/step - loss: 0.5498 - acc: 0.6792 - val_loss: 0.6051 - val_acc: 0.6604\n",
      "Epoch 271/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.4971 - acc: 0.7170 - val_loss: 0.6067 - val_acc: 0.6604\n",
      "Epoch 272/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5432 - acc: 0.7170 - val_loss: 0.6038 - val_acc: 0.6604\n",
      "Epoch 273/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5687 - acc: 0.6415 - val_loss: 0.6012 - val_acc: 0.6604\n",
      "Epoch 274/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5924 - acc: 0.6792 - val_loss: 0.5984 - val_acc: 0.6792\n",
      "Epoch 275/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5520 - acc: 0.6792 - val_loss: 0.5961 - val_acc: 0.6792\n",
      "Epoch 276/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5603 - acc: 0.6981 - val_loss: 0.5959 - val_acc: 0.6792\n",
      "Epoch 277/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5452 - acc: 0.6792 - val_loss: 0.5959 - val_acc: 0.6792\n",
      "Epoch 278/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5114 - acc: 0.7358 - val_loss: 0.5959 - val_acc: 0.6792\n",
      "Epoch 279/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5643 - acc: 0.6981 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 280/500\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.5134 - acc: 0.6981 - val_loss: 0.5997 - val_acc: 0.6604\n",
      "Epoch 281/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5611 - acc: 0.6792 - val_loss: 0.6051 - val_acc: 0.6604\n",
      "Epoch 282/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.6506 - acc: 0.6226 - val_loss: 0.6072 - val_acc: 0.6604\n",
      "Epoch 283/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5250 - acc: 0.7170 - val_loss: 0.6058 - val_acc: 0.6604\n",
      "Epoch 284/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5521 - acc: 0.6415 - val_loss: 0.6048 - val_acc: 0.6604\n",
      "Epoch 285/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5704 - acc: 0.6981 - val_loss: 0.6027 - val_acc: 0.6604\n",
      "Epoch 286/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5581 - acc: 0.7170 - val_loss: 0.6006 - val_acc: 0.6604\n",
      "Epoch 287/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5434 - acc: 0.7358 - val_loss: 0.5997 - val_acc: 0.6604\n",
      "Epoch 288/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5807 - acc: 0.6604 - val_loss: 0.6002 - val_acc: 0.6604\n",
      "Epoch 289/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5351 - acc: 0.7170 - val_loss: 0.5993 - val_acc: 0.6604\n",
      "Epoch 290/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6314 - acc: 0.6604 - val_loss: 0.5988 - val_acc: 0.6604\n",
      "Epoch 291/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5409 - acc: 0.6981 - val_loss: 0.5976 - val_acc: 0.6792\n",
      "Epoch 292/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5703 - acc: 0.6981 - val_loss: 0.5972 - val_acc: 0.6792\n",
      "Epoch 293/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5468 - acc: 0.7547 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 294/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5113 - acc: 0.781 - 0s 489us/step - loss: 0.5614 - acc: 0.7358 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 295/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5948 - acc: 0.7358 - val_loss: 0.5973 - val_acc: 0.6792\n",
      "Epoch 296/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5464 - acc: 0.7170 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 297/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5992 - acc: 0.7547 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 298/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5683 - acc: 0.7547 - val_loss: 0.5973 - val_acc: 0.6792\n",
      "Epoch 299/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5503 - acc: 0.6981 - val_loss: 0.5980 - val_acc: 0.6792\n",
      "Epoch 300/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5894 - acc: 0.6415 - val_loss: 0.5977 - val_acc: 0.6792\n",
      "Epoch 301/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5833 - acc: 0.6415 - val_loss: 0.5983 - val_acc: 0.6792\n",
      "Epoch 302/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5243 - acc: 0.7170 - val_loss: 0.5992 - val_acc: 0.6792\n",
      "Epoch 303/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5316 - acc: 0.6981 - val_loss: 0.5977 - val_acc: 0.6792\n",
      "Epoch 304/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5810 - acc: 0.6038 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 546us/step - loss: 0.5633 - acc: 0.6981 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 306/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5733 - acc: 0.6415 - val_loss: 0.5974 - val_acc: 0.6792\n",
      "Epoch 307/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.6085 - acc: 0.5472 - val_loss: 0.5989 - val_acc: 0.6792\n",
      "Epoch 308/500\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5319 - acc: 0.7170 - val_loss: 0.5998 - val_acc: 0.6792\n",
      "Epoch 309/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5568 - acc: 0.7170 - val_loss: 0.6012 - val_acc: 0.6604\n",
      "Epoch 310/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5489 - acc: 0.6981 - val_loss: 0.6015 - val_acc: 0.6604\n",
      "Epoch 311/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5199 - acc: 0.6604 - val_loss: 0.6013 - val_acc: 0.6604\n",
      "Epoch 312/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6103 - acc: 0.6981 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 313/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5199 - acc: 0.7170 - val_loss: 0.5975 - val_acc: 0.6792\n",
      "Epoch 314/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5818 - acc: 0.6604 - val_loss: 0.5975 - val_acc: 0.6792\n",
      "Epoch 315/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5795 - acc: 0.6981 - val_loss: 0.5964 - val_acc: 0.6792\n",
      "Epoch 316/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6183 - acc: 0.6226 - val_loss: 0.5967 - val_acc: 0.6792\n",
      "Epoch 317/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5859 - acc: 0.6604 - val_loss: 0.5975 - val_acc: 0.6792\n",
      "Epoch 318/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5735 - acc: 0.6792 - val_loss: 0.5979 - val_acc: 0.6792\n",
      "Epoch 319/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5767 - acc: 0.6981 - val_loss: 0.5971 - val_acc: 0.6792\n",
      "Epoch 320/500\n",
      "53/53 [==============================] - 0s 903us/step - loss: 0.5678 - acc: 0.6792 - val_loss: 0.5967 - val_acc: 0.6792\n",
      "Epoch 321/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5508 - acc: 0.6604 - val_loss: 0.5961 - val_acc: 0.6792\n",
      "Epoch 322/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5407 - acc: 0.7358 - val_loss: 0.5960 - val_acc: 0.6792\n",
      "Epoch 323/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5550 - acc: 0.6981 - val_loss: 0.5963 - val_acc: 0.6792\n",
      "Epoch 324/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5765 - acc: 0.6792 - val_loss: 0.5967 - val_acc: 0.6792\n",
      "Epoch 325/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5568 - acc: 0.6981 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 326/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5796 - acc: 0.6415 - val_loss: 0.5977 - val_acc: 0.6792\n",
      "Epoch 327/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5694 - acc: 0.6792 - val_loss: 0.5998 - val_acc: 0.6792\n",
      "Epoch 328/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5958 - acc: 0.7358 - val_loss: 0.6007 - val_acc: 0.6792\n",
      "Epoch 329/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5327 - acc: 0.7358 - val_loss: 0.6012 - val_acc: 0.6604\n",
      "Epoch 330/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5143 - acc: 0.7358 - val_loss: 0.6006 - val_acc: 0.6792\n",
      "Epoch 331/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5512 - acc: 0.6981 - val_loss: 0.5984 - val_acc: 0.6792\n",
      "Epoch 332/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5191 - acc: 0.7358 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 333/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5566 - acc: 0.7358 - val_loss: 0.5977 - val_acc: 0.6792\n",
      "Epoch 334/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5597 - acc: 0.6981 - val_loss: 0.5980 - val_acc: 0.6792\n",
      "Epoch 335/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5621 - acc: 0.7358 - val_loss: 0.5977 - val_acc: 0.6792\n",
      "Epoch 336/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5775 - acc: 0.6415 - val_loss: 0.5987 - val_acc: 0.6792\n",
      "Epoch 337/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5846 - acc: 0.7358 - val_loss: 0.6023 - val_acc: 0.6792\n",
      "Epoch 338/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5679 - acc: 0.7170 - val_loss: 0.6095 - val_acc: 0.6604\n",
      "Epoch 339/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5212 - acc: 0.7358 - val_loss: 0.6143 - val_acc: 0.6604\n",
      "Epoch 340/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5744 - acc: 0.6604 - val_loss: 0.6171 - val_acc: 0.6604\n",
      "Epoch 341/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5889 - acc: 0.7925 - val_loss: 0.6157 - val_acc: 0.6604\n",
      "Epoch 342/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6034 - acc: 0.6604 - val_loss: 0.6096 - val_acc: 0.6604\n",
      "Epoch 343/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5198 - acc: 0.7358 - val_loss: 0.6037 - val_acc: 0.6792\n",
      "Epoch 344/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5553 - acc: 0.6792 - val_loss: 0.6022 - val_acc: 0.6792\n",
      "Epoch 345/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5453 - acc: 0.6792 - val_loss: 0.6024 - val_acc: 0.6981\n",
      "Epoch 346/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5399 - acc: 0.6604 - val_loss: 0.6062 - val_acc: 0.6604\n",
      "Epoch 347/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5418 - acc: 0.6981 - val_loss: 0.6134 - val_acc: 0.6604\n",
      "Epoch 348/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5958 - acc: 0.7358 - val_loss: 0.6214 - val_acc: 0.6604\n",
      "Epoch 349/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6135 - acc: 0.6981 - val_loss: 0.6215 - val_acc: 0.6604\n",
      "Epoch 350/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.6337 - acc: 0.6226 - val_loss: 0.6126 - val_acc: 0.6604\n",
      "Epoch 351/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5688 - acc: 0.6415 - val_loss: 0.6072 - val_acc: 0.6604\n",
      "Epoch 352/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5792 - acc: 0.6981 - val_loss: 0.6054 - val_acc: 0.6792\n",
      "Epoch 353/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5619 - acc: 0.6604 - val_loss: 0.6039 - val_acc: 0.6981\n",
      "Epoch 354/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5956 - acc: 0.6415 - val_loss: 0.6033 - val_acc: 0.6981\n",
      "Epoch 355/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.4997 - acc: 0.7547 - val_loss: 0.6033 - val_acc: 0.6981\n",
      "Epoch 356/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5629 - acc: 0.7170 - val_loss: 0.6035 - val_acc: 0.6981\n",
      "Epoch 357/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5699 - acc: 0.6604 - val_loss: 0.6035 - val_acc: 0.6981\n",
      "Epoch 358/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6140 - acc: 0.6226 - val_loss: 0.6038 - val_acc: 0.6981\n",
      "Epoch 359/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6005 - acc: 0.6792 - val_loss: 0.6066 - val_acc: 0.6792\n",
      "Epoch 360/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5674 - acc: 0.6792 - val_loss: 0.6061 - val_acc: 0.6792\n",
      "Epoch 361/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5873 - acc: 0.6792 - val_loss: 0.6035 - val_acc: 0.6792\n",
      "Epoch 362/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6207 - acc: 0.6415 - val_loss: 0.6012 - val_acc: 0.6792\n",
      "Epoch 363/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5634 - acc: 0.6981 - val_loss: 0.6006 - val_acc: 0.6792\n",
      "Epoch 364/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.6101 - acc: 0.6604 - val_loss: 0.6010 - val_acc: 0.6792\n",
      "Epoch 365/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5945 - acc: 0.7358 - val_loss: 0.6019 - val_acc: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5699 - acc: 0.6415 - val_loss: 0.6035 - val_acc: 0.6604\n",
      "Epoch 367/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5456 - acc: 0.6792 - val_loss: 0.6049 - val_acc: 0.6604\n",
      "Epoch 368/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5744 - acc: 0.7358 - val_loss: 0.6055 - val_acc: 0.6604\n",
      "Epoch 369/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5855 - acc: 0.6604 - val_loss: 0.6052 - val_acc: 0.6604\n",
      "Epoch 370/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5924 - acc: 0.6415 - val_loss: 0.6011 - val_acc: 0.6792\n",
      "Epoch 371/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5081 - acc: 0.7170 - val_loss: 0.5989 - val_acc: 0.6792\n",
      "Epoch 372/500\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5484 - acc: 0.7358 - val_loss: 0.5980 - val_acc: 0.6792\n",
      "Epoch 373/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5540 - acc: 0.7170 - val_loss: 0.5989 - val_acc: 0.6792\n",
      "Epoch 374/500\n",
      "53/53 [==============================] - 0s 659us/step - loss: 0.5696 - acc: 0.6981 - val_loss: 0.5988 - val_acc: 0.6792\n",
      "Epoch 375/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5448 - acc: 0.7358 - val_loss: 0.5991 - val_acc: 0.6792\n",
      "Epoch 376/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5709 - acc: 0.7170 - val_loss: 0.5995 - val_acc: 0.6792\n",
      "Epoch 377/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5810 - acc: 0.6604 - val_loss: 0.6019 - val_acc: 0.6792\n",
      "Epoch 378/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5584 - acc: 0.7358 - val_loss: 0.6027 - val_acc: 0.6604\n",
      "Epoch 379/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.4949 - acc: 0.6792 - val_loss: 0.6025 - val_acc: 0.6604\n",
      "Epoch 380/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5901 - acc: 0.6792 - val_loss: 0.6040 - val_acc: 0.6604\n",
      "Epoch 381/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5579 - acc: 0.7358 - val_loss: 0.6028 - val_acc: 0.6604\n",
      "Epoch 382/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5249 - acc: 0.7170 - val_loss: 0.6003 - val_acc: 0.6792\n",
      "Epoch 383/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5443 - acc: 0.6981 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 384/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6209 - acc: 0.6415 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 385/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5251 - acc: 0.6792 - val_loss: 0.5969 - val_acc: 0.6792\n",
      "Epoch 386/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5438 - acc: 0.6415 - val_loss: 0.5970 - val_acc: 0.6792\n",
      "Epoch 387/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5446 - acc: 0.7170 - val_loss: 0.5962 - val_acc: 0.6792\n",
      "Epoch 388/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5623 - acc: 0.6981 - val_loss: 0.5974 - val_acc: 0.6792\n",
      "Epoch 389/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5627 - acc: 0.6604 - val_loss: 0.6020 - val_acc: 0.6604\n",
      "Epoch 390/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5522 - acc: 0.6981 - val_loss: 0.6077 - val_acc: 0.6604\n",
      "Epoch 391/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5679 - acc: 0.6792 - val_loss: 0.6083 - val_acc: 0.6604\n",
      "Epoch 392/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5875 - acc: 0.6415 - val_loss: 0.6076 - val_acc: 0.6604\n",
      "Epoch 393/500\n",
      "53/53 [==============================] - 0s 677us/step - loss: 0.5801 - acc: 0.6981 - val_loss: 0.6024 - val_acc: 0.6604\n",
      "Epoch 394/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6067 - acc: 0.6981 - val_loss: 0.5993 - val_acc: 0.6792\n",
      "Epoch 395/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.6186 - acc: 0.6604 - val_loss: 0.5967 - val_acc: 0.6792\n",
      "Epoch 396/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5403 - acc: 0.7547 - val_loss: 0.5966 - val_acc: 0.6792\n",
      "Epoch 397/500\n",
      "53/53 [==============================] - 0s 376us/step - loss: 0.5818 - acc: 0.6981 - val_loss: 0.5965 - val_acc: 0.6792\n",
      "Epoch 398/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5789 - acc: 0.7170 - val_loss: 0.5968 - val_acc: 0.6792\n",
      "Epoch 399/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.6070 - acc: 0.6792 - val_loss: 0.5999 - val_acc: 0.6792\n",
      "Epoch 400/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5353 - acc: 0.7170 - val_loss: 0.6003 - val_acc: 0.6792\n",
      "Epoch 401/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.6122 - acc: 0.6415 - val_loss: 0.6000 - val_acc: 0.6792\n",
      "Epoch 402/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.6012 - acc: 0.718 - 0s 470us/step - loss: 0.5735 - acc: 0.7170 - val_loss: 0.6029 - val_acc: 0.6792\n",
      "Epoch 403/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.4981 - acc: 0.7358 - val_loss: 0.6066 - val_acc: 0.6604\n",
      "Epoch 404/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6069 - acc: 0.6792 - val_loss: 0.6074 - val_acc: 0.6604\n",
      "Epoch 405/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5429 - acc: 0.7358 - val_loss: 0.6077 - val_acc: 0.6604\n",
      "Epoch 406/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5445 - acc: 0.6226 - val_loss: 0.6055 - val_acc: 0.6604\n",
      "Epoch 407/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.4980 - acc: 0.7358 - val_loss: 0.6035 - val_acc: 0.6792\n",
      "Epoch 408/500\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5651 - acc: 0.6792 - val_loss: 0.6010 - val_acc: 0.6792\n",
      "Epoch 409/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5434 - acc: 0.6981 - val_loss: 0.5993 - val_acc: 0.6792\n",
      "Epoch 410/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5747 - acc: 0.6604 - val_loss: 0.5988 - val_acc: 0.6792\n",
      "Epoch 411/500\n",
      "53/53 [==============================] - 0s 451us/step - loss: 0.5752 - acc: 0.6792 - val_loss: 0.5999 - val_acc: 0.6981\n",
      "Epoch 412/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5797 - acc: 0.7170 - val_loss: 0.6007 - val_acc: 0.6792\n",
      "Epoch 413/500\n",
      "53/53 [==============================] - 0s 564us/step - loss: 0.5879 - acc: 0.6415 - val_loss: 0.6000 - val_acc: 0.6981\n",
      "Epoch 414/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.6174 - acc: 0.6038 - val_loss: 0.5991 - val_acc: 0.6792\n",
      "Epoch 415/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6012 - acc: 0.6981 - val_loss: 0.6001 - val_acc: 0.6792\n",
      "Epoch 416/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5060 - acc: 0.7170 - val_loss: 0.6009 - val_acc: 0.6792\n",
      "Epoch 417/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5152 - acc: 0.6981 - val_loss: 0.6011 - val_acc: 0.6792\n",
      "Epoch 418/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5508 - acc: 0.6981 - val_loss: 0.6018 - val_acc: 0.6792\n",
      "Epoch 419/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5854 - acc: 0.6226 - val_loss: 0.6015 - val_acc: 0.6792\n",
      "Epoch 420/500\n",
      "53/53 [==============================] - ETA: 0s - loss: 0.5958 - acc: 0.687 - 0s 508us/step - loss: 0.5277 - acc: 0.7170 - val_loss: 0.5999 - val_acc: 0.6792\n",
      "Epoch 421/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.4835 - acc: 0.7547 - val_loss: 0.5996 - val_acc: 0.6981\n",
      "Epoch 422/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5605 - acc: 0.6981 - val_loss: 0.6003 - val_acc: 0.6981\n",
      "Epoch 423/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5342 - acc: 0.7170 - val_loss: 0.6014 - val_acc: 0.6981\n",
      "Epoch 424/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5218 - acc: 0.7170 - val_loss: 0.6010 - val_acc: 0.6981\n",
      "Epoch 425/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5961 - acc: 0.6038 - val_loss: 0.6009 - val_acc: 0.6981\n",
      "Epoch 426/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 0s 433us/step - loss: 0.6096 - acc: 0.6415 - val_loss: 0.6009 - val_acc: 0.6981\n",
      "Epoch 427/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5438 - acc: 0.6981 - val_loss: 0.6001 - val_acc: 0.6981\n",
      "Epoch 428/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5265 - acc: 0.6415 - val_loss: 0.6006 - val_acc: 0.6792\n",
      "Epoch 429/500\n",
      "53/53 [==============================] - 0s 490us/step - loss: 0.5781 - acc: 0.6604 - val_loss: 0.6038 - val_acc: 0.6792\n",
      "Epoch 430/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5371 - acc: 0.7358 - val_loss: 0.6098 - val_acc: 0.6604\n",
      "Epoch 431/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5770 - acc: 0.6792 - val_loss: 0.6115 - val_acc: 0.6604\n",
      "Epoch 432/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5488 - acc: 0.6981 - val_loss: 0.6114 - val_acc: 0.6604\n",
      "Epoch 433/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5586 - acc: 0.6981 - val_loss: 0.6087 - val_acc: 0.6604\n",
      "Epoch 434/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5741 - acc: 0.7358 - val_loss: 0.6084 - val_acc: 0.6604\n",
      "Epoch 435/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5971 - acc: 0.6604 - val_loss: 0.6070 - val_acc: 0.6604\n",
      "Epoch 436/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5541 - acc: 0.6792 - val_loss: 0.6041 - val_acc: 0.6792\n",
      "Epoch 437/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5415 - acc: 0.6981 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 438/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.6442 - acc: 0.6226 - val_loss: 0.6020 - val_acc: 0.6981\n",
      "Epoch 439/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5958 - acc: 0.6415 - val_loss: 0.6018 - val_acc: 0.6981\n",
      "Epoch 440/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5294 - acc: 0.7358 - val_loss: 0.6043 - val_acc: 0.6792\n",
      "Epoch 441/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5634 - acc: 0.6604 - val_loss: 0.6062 - val_acc: 0.6604\n",
      "Epoch 442/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5549 - acc: 0.6604 - val_loss: 0.6090 - val_acc: 0.6604\n",
      "Epoch 443/500\n",
      "53/53 [==============================] - 0s 565us/step - loss: 0.5592 - acc: 0.6415 - val_loss: 0.6136 - val_acc: 0.6604\n",
      "Epoch 444/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5840 - acc: 0.7170 - val_loss: 0.6133 - val_acc: 0.6604\n",
      "Epoch 445/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5589 - acc: 0.7358 - val_loss: 0.6084 - val_acc: 0.6604\n",
      "Epoch 446/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.6196 - acc: 0.6226 - val_loss: 0.6048 - val_acc: 0.6792\n",
      "Epoch 447/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5292 - acc: 0.6981 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 448/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5821 - acc: 0.6792 - val_loss: 0.6022 - val_acc: 0.6981\n",
      "Epoch 449/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.6167 - acc: 0.6038 - val_loss: 0.6020 - val_acc: 0.6981\n",
      "Epoch 450/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5008 - acc: 0.7547 - val_loss: 0.6034 - val_acc: 0.6981\n",
      "Epoch 451/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5347 - acc: 0.7547 - val_loss: 0.6089 - val_acc: 0.6604\n",
      "Epoch 452/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5268 - acc: 0.6981 - val_loss: 0.6158 - val_acc: 0.6604\n",
      "Epoch 453/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5554 - acc: 0.6792 - val_loss: 0.6176 - val_acc: 0.6604\n",
      "Epoch 454/500\n",
      "53/53 [==============================] - 0s 471us/step - loss: 0.5691 - acc: 0.6792 - val_loss: 0.6157 - val_acc: 0.6604\n",
      "Epoch 455/500\n",
      "53/53 [==============================] - 0s 358us/step - loss: 0.5547 - acc: 0.7170 - val_loss: 0.6092 - val_acc: 0.6604\n",
      "Epoch 456/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5747 - acc: 0.6604 - val_loss: 0.6072 - val_acc: 0.6604\n",
      "Epoch 457/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.6226 - acc: 0.7170 - val_loss: 0.6049 - val_acc: 0.6792\n",
      "Epoch 458/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5522 - acc: 0.7170 - val_loss: 0.6045 - val_acc: 0.6792\n",
      "Epoch 459/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5918 - acc: 0.7170 - val_loss: 0.6034 - val_acc: 0.6981\n",
      "Epoch 460/500\n",
      "53/53 [==============================] - 0s 395us/step - loss: 0.5424 - acc: 0.7170 - val_loss: 0.6044 - val_acc: 0.6792\n",
      "Epoch 461/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5175 - acc: 0.7925 - val_loss: 0.6058 - val_acc: 0.6792\n",
      "Epoch 462/500\n",
      "53/53 [==============================] - 0s 508us/step - loss: 0.5403 - acc: 0.7170 - val_loss: 0.6088 - val_acc: 0.6604\n",
      "Epoch 463/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5831 - acc: 0.6792 - val_loss: 0.6102 - val_acc: 0.6604\n",
      "Epoch 464/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5368 - acc: 0.7170 - val_loss: 0.6071 - val_acc: 0.6604\n",
      "Epoch 465/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5870 - acc: 0.6792 - val_loss: 0.6023 - val_acc: 0.6792\n",
      "Epoch 466/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5034 - acc: 0.7358 - val_loss: 0.6015 - val_acc: 0.6792\n",
      "Epoch 467/500\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5812 - acc: 0.6981 - val_loss: 0.6011 - val_acc: 0.6981\n",
      "Epoch 468/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.4991 - acc: 0.7170 - val_loss: 0.6011 - val_acc: 0.6981\n",
      "Epoch 469/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5099 - acc: 0.7547 - val_loss: 0.6012 - val_acc: 0.6792\n",
      "Epoch 470/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5326 - acc: 0.7170 - val_loss: 0.6015 - val_acc: 0.6792\n",
      "Epoch 471/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5434 - acc: 0.7547 - val_loss: 0.6023 - val_acc: 0.6792\n",
      "Epoch 472/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5395 - acc: 0.7358 - val_loss: 0.6030 - val_acc: 0.6792\n",
      "Epoch 473/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5223 - acc: 0.7547 - val_loss: 0.6024 - val_acc: 0.6792\n",
      "Epoch 474/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5566 - acc: 0.6981 - val_loss: 0.6027 - val_acc: 0.6792\n",
      "Epoch 475/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5248 - acc: 0.6792 - val_loss: 0.6027 - val_acc: 0.6792\n",
      "Epoch 476/500\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5558 - acc: 0.6415 - val_loss: 0.6030 - val_acc: 0.6792\n",
      "Epoch 477/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5484 - acc: 0.6981 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 478/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5291 - acc: 0.6981 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 479/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5297 - acc: 0.6792 - val_loss: 0.6032 - val_acc: 0.6792\n",
      "Epoch 480/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5360 - acc: 0.7170 - val_loss: 0.6047 - val_acc: 0.6792\n",
      "Epoch 481/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5698 - acc: 0.7170 - val_loss: 0.6051 - val_acc: 0.6792\n",
      "Epoch 482/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6061 - acc: 0.6038 - val_loss: 0.6044 - val_acc: 0.6792\n",
      "Epoch 483/500\n",
      "53/53 [==============================] - 0s 414us/step - loss: 0.5417 - acc: 0.7170 - val_loss: 0.6038 - val_acc: 0.6792\n",
      "Epoch 484/500\n",
      "53/53 [==============================] - 0s 433us/step - loss: 0.5380 - acc: 0.6981 - val_loss: 0.6038 - val_acc: 0.6792\n",
      "Epoch 485/500\n",
      "53/53 [==============================] - 0s 621us/step - loss: 0.5445 - acc: 0.6792 - val_loss: 0.6036 - val_acc: 0.6792\n",
      "Epoch 486/500\n",
      "53/53 [==============================] - 0s 583us/step - loss: 0.5649 - acc: 0.6415 - val_loss: 0.6019 - val_acc: 0.6981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5041 - acc: 0.7736 - val_loss: 0.6018 - val_acc: 0.6981\n",
      "Epoch 488/500\n",
      "53/53 [==============================] - 0s 602us/step - loss: 0.5737 - acc: 0.6226 - val_loss: 0.6020 - val_acc: 0.6981\n",
      "Epoch 489/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5922 - acc: 0.6038 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 490/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.5734 - acc: 0.6604 - val_loss: 0.6034 - val_acc: 0.6792\n",
      "Epoch 491/500\n",
      "53/53 [==============================] - 0s 545us/step - loss: 0.5331 - acc: 0.6415 - val_loss: 0.6033 - val_acc: 0.6792\n",
      "Epoch 492/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6043 - acc: 0.6415 - val_loss: 0.6026 - val_acc: 0.6981\n",
      "Epoch 493/500\n",
      "53/53 [==============================] - 0s 546us/step - loss: 0.6027 - acc: 0.6038 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "Epoch 494/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5390 - acc: 0.7170 - val_loss: 0.6030 - val_acc: 0.6981\n",
      "Epoch 495/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5288 - acc: 0.6604 - val_loss: 0.6046 - val_acc: 0.6792\n",
      "Epoch 496/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5353 - acc: 0.6981 - val_loss: 0.6062 - val_acc: 0.6604\n",
      "Epoch 497/500\n",
      "53/53 [==============================] - 0s 489us/step - loss: 0.5239 - acc: 0.7170 - val_loss: 0.6093 - val_acc: 0.6604\n",
      "Epoch 498/500\n",
      "53/53 [==============================] - 0s 452us/step - loss: 0.5684 - acc: 0.7170 - val_loss: 0.6085 - val_acc: 0.6604\n",
      "Epoch 499/500\n",
      "53/53 [==============================] - 0s 470us/step - loss: 0.5109 - acc: 0.6981 - val_loss: 0.6046 - val_acc: 0.6792\n",
      "Epoch 500/500\n",
      "53/53 [==============================] - 0s 527us/step - loss: 0.5507 - acc: 0.6981 - val_loss: 0.6025 - val_acc: 0.6981\n",
      "53/53 [==============================] - 0s 245us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6024584432817855, 0.6981132142948654]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# following https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/_index.ipynb\n",
    "# as a tutorial\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(units=4,input_shape=(5,)))\n",
    "model.add(layers.Dense(64, activation='selu'))\n",
    "model.add(layers.Dropout (0.3))\n",
    "model.add(layers.Dense(64, activation='selu'))\n",
    "model.add(layers.Dense(64, activation='selu'))\n",
    "model.add(layers.Dropout (0.3))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='Adamax',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(np.array(train_inputs), np.array(train_outputs), epochs=500,\n",
    "              validation_data=(np.array(test_inputs), np.array(test_outputs)))\n",
    "\n",
    "model.evaluate(np.array(test_inputs), np.array(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
